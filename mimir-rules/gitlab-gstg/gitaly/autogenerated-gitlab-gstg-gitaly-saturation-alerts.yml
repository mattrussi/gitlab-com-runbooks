# WARNING. DO NOT EDIT THIS FILE BY HAND. USE ./mimir-rules-jsonnet/saturation.jsonnet TO GENERATE IT
# YOUR CHANGES WILL BE OVERRIDDEN
groups:
- name: GitLab Component Saturation Statistics
  interval: 5m
  rules:
  - record: gitlab_component_saturation:ratio_quantile95_1w
    expr: quantile_over_time(0.95, gitlab_component_saturation:ratio{env="gstg",type="gitaly"}[1w])
  - record: gitlab_component_saturation:ratio_quantile99_1w
    expr: quantile_over_time(0.99, gitlab_component_saturation:ratio{env="gstg",type="gitaly"}[1w])
  - record: gitlab_component_saturation:ratio_quantile95_1h
    expr: quantile_over_time(0.95, gitlab_component_saturation:ratio{env="gstg",type="gitaly"}[1h])
  - record: gitlab_component_saturation:ratio_quantile99_1h
    expr: quantile_over_time(0.99, gitlab_component_saturation:ratio{env="gstg",type="gitaly"}[1h])
  - record: gitlab_component_saturation:ratio_avg_1h
    expr: avg_over_time(gitlab_component_saturation:ratio{env="gstg",type="gitaly"}[1h])
- name: GitLab Saturation Alerts
  interval: 1m
  rules:
  - alert: component_saturation_slo_out_of_bounds:cgroup_memory
    for: 5m
    annotations:
      title: The Cgroup Memory Utilization per Node resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage) has a saturation exceeding SLO and
        is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Cgroup Memory Utilization per Node resource:

        Cgroup memory utilization per node.

        Some services, notably Gitaly, are configured to run within a cgroup with a memory limit lower than the memory limit for the node. This ensures that a traffic spike to Gitaly does not affect other services on the node.

        If this resource is becoming saturated, this may indicate traffic spikes to Gitaly, abuse or possibly resource leaks in the application. Gitaly or other git processes may be killed by the OOM killer when this resource is saturated.
      grafana_dashboard_id: alerts-sat_cgroup_memory
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_cgroup_memory?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_datasource_id: mimir-gitlab-gstg
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2265664609"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment,fqdn,shard,stage,tier,type) (
          clamp_min(
            clamp_max(
              (
                container_memory_usage_bytes{id="/system.slice/gitlab-runsvdir.service", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"} -
                container_memory_cache{id="/system.slice/gitlab-runsvdir.service", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"} -
                container_memory_swap{id="/system.slice/gitlab-runsvdir.service", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              )
              /
              container_spec_memory_limit_bytes{id="/system.slice/gitlab-runsvdir.service", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              ,
              1)
          ,
          0)
        )
      promql_template_1: |
        max by(environment,fqdn,shard,stage,tier,type) (
          clamp_min(
            clamp_max(
              (
                container_memory_usage_bytes{id="/system.slice/gitlab-runsvdir.service", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"} -
                container_memory_cache{id="/system.slice/gitlab-runsvdir.service", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"} -
                container_memory_swap{id="/system.slice/gitlab-runsvdir.service", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              )
              /
              container_spec_memory_limit_bytes{id="/system.slice/gitlab-runsvdir.service", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
    expr: |
      gitlab_component_saturation:ratio{component="cgroup_memory",env="gstg",type="gitaly"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="cgroup_memory"}
  - alert: component_saturation_slo_out_of_bounds:cpu
    for: 5m
    annotations:
      title: The Average Service CPU Utilization resource of the {{ $labels.type }}
        service ({{ $labels.stage }} stage) has a saturation exceeding SLO and is
        close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Average Service CPU Utilization resource:

        This resource measures average CPU utilization across an all cores in a service fleet. If it is becoming saturated, it may indicate that the fleet needs horizontal or vertical scaling.
      grafana_dashboard_id: alerts-sat_cpu
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_cpu?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_datasource_id: mimir-gitlab-gstg
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1465724101"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment,shard,stage,tier,type) (
          clamp_min(
            clamp_max(
              1 - avg by (environment,shard,stage,tier,type) (
                rate(node_cpu_seconds_total{mode="idle", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m])
              )
              ,
              1)
          ,
          0)
        )
      promql_template_1: |
        max by(environment,shard,stage,tier,type) (
          clamp_min(
            clamp_max(
              1 - avg by (environment,shard,stage,tier,type) (
                rate(node_cpu_seconds_total{mode="idle", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m])
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s3
    expr: |
      gitlab_component_saturation:ratio{component="cpu",env="gstg",type="gitaly"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="cpu"}
  - alert: component_saturation_slo_out_of_bounds:disk_inodes
    for: 15m
    annotations:
      title: The Disk inode Utilization per Device per Node resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage) has a saturation exceeding SLO and
        is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Disk inode Utilization per Device per Node resource:

        Disk inode utilization per device per node.

        If this is too high, its possible that a directory is filling up with files. Consider logging in an checking temp directories for large numbers of files
      grafana_dashboard_id: alerts-sat_disk_inodes
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_disk_inodes?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_datasource_id: mimir-gitlab-gstg
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "39965907"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(device,environment,fqdn,shard,stage,tier,type) (
          clamp_min(
            clamp_max(
              1 - (
                node_filesystem_files_free{fstype=~"(ext.|xfs)", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
                /
                node_filesystem_files{fstype=~"(ext.|xfs)", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              )
              ,
              1)
          ,
          0)
        )
      promql_template_1: |
        max by(device,environment,fqdn,shard,stage,tier,type) (
          clamp_min(
            clamp_max(
              1 - (
                node_filesystem_files_free{fstype=~"(ext.|xfs)", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
                /
                node_filesystem_files{fstype=~"(ext.|xfs)", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      pager: pagerduty
      rules_domain: general
      severity: s2
    expr: |
      gitlab_component_saturation:ratio{component="disk_inodes",env="gstg",type="gitaly"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="disk_inodes"}
  - alert: ComponentResourceRunningOut_disk_inodes
    for: 15m
    annotations:
      title: The Disk inode Utilization per Device per Node resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage) is on track to hit capacity within
        6h
      description: |
        This means that this resource is growing rapidly and is predicted to exceed saturation threshold within 6h.

        Details of the Disk inode Utilization per Device per Node resource:

        Disk inode utilization per device per node.

        If this is too high, its possible that a directory is filling up with files. Consider logging in an checking temp directories for large numbers of files
      grafana_dashboard_id: alerts-sat_disk_inodes
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_disk_inodes?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_datasource_id: mimir-gitlab-gstg
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "39965907"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(device,environment,fqdn,shard,stage,tier,type) (
          clamp_min(
            clamp_max(
              1 - (
                node_filesystem_files_free{fstype=~"(ext.|xfs)", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
                /
                node_filesystem_files{fstype=~"(ext.|xfs)", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              )
              ,
              1)
          ,
          0)
        )
      promql_template_1: |
        max by(device,environment,fqdn,shard,stage,tier,type) (
          clamp_min(
            clamp_max(
              1 - (
                node_filesystem_files_free{fstype=~"(ext.|xfs)", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
                /
                node_filesystem_files{fstype=~"(ext.|xfs)", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      linear_prediction_saturation_alert: 6h
      pager: pagerduty
      rules_domain: general
      severity: s2
    expr: |
      predict_linear(gitlab_component_saturation:ratio{component="disk_inodes",env="gstg",type="gitaly"}[6h], 21600)
      > on (component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="disk_inodes"}
  - alert: component_saturation_slo_out_of_bounds:disk_maximum_capacity
    for: 5m
    annotations:
      title: The Maximum per-disk capacity resource of the {{ $labels.type }} service
        ({{ $labels.stage }} stage) has a saturation exceeding SLO and is close to
        its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Maximum per-disk capacity resource:

        The maximum capacity for a single disk can be limited by the cloud provider. This tracks the saturation as a ratio of the storage utilization to the maximum size limit enforced per disk.

        In order to resolve a saturation alert, storage needed on a single disk needs to be reduced. Possible ways of doing this include reducing utilization overall or partitioning data across multiple disks.

        (64*2^40) = 64TiB is the maximum value for many types of GCP disks, see https://cloud.google.com/compute/docs/disks#introduction.
      grafana_dashboard_id: alerts-sat_gcp_maximum_disk_capacity
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_gcp_maximum_disk_capacity?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_datasource_id: mimir-gitlab-gstg
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1042809451"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(device,environment,fqdn,shard,stage,tier,type) (
          clamp_min(
            clamp_max(
              max by (device,environment,fqdn,shard,stage,tier,type) (
                node_filesystem_size_bytes{fstype=~"ext.|xfs", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"} - node_filesystem_avail_bytes{fstype=~"ext.|xfs", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              ) / (64*2^40)
              ,
              1)
          ,
          0)
        )
      promql_template_1: |
        max by(device,environment,fqdn,shard,stage,tier,type) (
          clamp_min(
            clamp_max(
              max by (device,environment,fqdn,shard,stage,tier,type) (
                node_filesystem_size_bytes{fstype=~"ext.|xfs", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"} - node_filesystem_avail_bytes{fstype=~"ext.|xfs", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              ) / (64*2^40)
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      pager: pagerduty
      rules_domain: general
      severity: s1
    expr: |
      gitlab_component_saturation:ratio{component="disk_maximum_capacity",env="gstg",type="gitaly"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="disk_maximum_capacity"}
  - alert: component_saturation_slo_out_of_bounds:disk_space
    for: 15m
    annotations:
      title: The Disk Space Utilization per Device per Node resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage) has a saturation exceeding SLO and
        is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Disk Space Utilization per Device per Node resource:

        Disk space utilization per device per node.
      grafana_dashboard_id: alerts-sat_disk_space
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_disk_space?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_datasource_id: mimir-gitlab-gstg
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2661375984"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(device,environment,fqdn,shard,stage,tier,type) (
          clamp_min(
            clamp_max(
              (
                1 - node_filesystem_avail_bytes{fstype=~"ext.|xfs", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"} / node_filesystem_size_bytes{fstype=~"ext.|xfs", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              )
              ,
              1)
          ,
          0)
        )
      promql_template_1: |
        max by(device,environment,fqdn,shard,stage,tier,type) (
          clamp_min(
            clamp_max(
              (
                1 - node_filesystem_avail_bytes{fstype=~"ext.|xfs", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"} / node_filesystem_size_bytes{fstype=~"ext.|xfs", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      pager: pagerduty
      rules_domain: general
      severity: s2
    expr: |
      gitlab_component_saturation:ratio{component="disk_space",env="gstg",type="gitaly"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="disk_space"}
  - alert: ComponentResourceRunningOut_disk_space
    for: 15m
    annotations:
      title: The Disk Space Utilization per Device per Node resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage) is on track to hit capacity within
        6h
      description: |
        This means that this resource is growing rapidly and is predicted to exceed saturation threshold within 6h.

        Details of the Disk Space Utilization per Device per Node resource:

        Disk space utilization per device per node.
      grafana_dashboard_id: alerts-sat_disk_space
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_disk_space?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_datasource_id: mimir-gitlab-gstg
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2661375984"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(device,environment,fqdn,shard,stage,tier,type) (
          clamp_min(
            clamp_max(
              (
                1 - node_filesystem_avail_bytes{fstype=~"ext.|xfs", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"} / node_filesystem_size_bytes{fstype=~"ext.|xfs", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              )
              ,
              1)
          ,
          0)
        )
      promql_template_1: |
        max by(device,environment,fqdn,shard,stage,tier,type) (
          clamp_min(
            clamp_max(
              (
                1 - node_filesystem_avail_bytes{fstype=~"ext.|xfs", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"} / node_filesystem_size_bytes{fstype=~"ext.|xfs", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      linear_prediction_saturation_alert: 6h
      pager: pagerduty
      rules_domain: general
      severity: s2
    expr: |
      predict_linear(gitlab_component_saturation:ratio{component="disk_space",env="gstg",type="gitaly"}[6h], 21600)
      > on (component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="disk_space"}
  - alert: component_saturation_slo_out_of_bounds:disk_sustained_read_iops
    for: 25m
    annotations:
      title: The Disk Sustained Read IOPS Utilization per Node resource of the {{
        $labels.type }} service ({{ $labels.stage }} stage) has a saturation exceeding
        SLO and is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Disk Sustained Read IOPS Utilization per Node resource:

        Disk sustained read IOPS utilization per node.
      grafana_dashboard_id: alerts-sat_disk_sus_read_iops
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_disk_sus_read_iops?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_datasource_id: mimir-gitlab-gstg
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "3942129027"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(device,environment,fqdn,shard,stage,tier,type) (
          clamp_min(
            clamp_max(
              rate(node_disk_reads_completed_total{device!="sda", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[20m])
              /
              node_disk_max_read_iops{device!="sda", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              ,
              1)
          ,
          0)
        )
      promql_template_1: |
        max by(device,environment,fqdn,shard,stage,tier,type) (
          clamp_min(
            clamp_max(
              rate(node_disk_reads_completed_total{device!="sda", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[20m])
              /
              node_disk_max_read_iops{device!="sda", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s3
    expr: |
      gitlab_component_saturation:ratio{component="disk_sustained_read_iops",env="gstg",type="gitaly"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="disk_sustained_read_iops"}
  - alert: component_saturation_slo_out_of_bounds:disk_sustained_read_throughput
    for: 25m
    annotations:
      title: The Disk Sustained Read Throughput Utilization per Node resource of the
        {{ $labels.type }} service ({{ $labels.stage }} stage) has a saturation exceeding
        SLO and is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Disk Sustained Read Throughput Utilization per Node resource:

        Disk sustained read throughput utilization per node.
      grafana_dashboard_id: alerts-sat_disk_sus_read_throughput
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_disk_sus_read_throughput?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_datasource_id: mimir-gitlab-gstg
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "3120931940"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(device,environment,fqdn,shard,stage,tier,type) (
          clamp_min(
            clamp_max(
              rate(node_disk_read_bytes_total{device!="sda", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[20m])
              /
              node_disk_max_read_bytes_seconds{device!="sda", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              ,
              1)
          ,
          0)
        )
      promql_template_1: |
        max by(device,environment,fqdn,shard,stage,tier,type) (
          clamp_min(
            clamp_max(
              rate(node_disk_read_bytes_total{device!="sda", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[20m])
              /
              node_disk_max_read_bytes_seconds{device!="sda", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s3
    expr: |
      gitlab_component_saturation:ratio{component="disk_sustained_read_throughput",env="gstg",type="gitaly"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="disk_sustained_read_throughput"}
  - alert: component_saturation_slo_out_of_bounds:disk_sustained_write_iops
    for: 25m
    annotations:
      title: The Disk Sustained Write IOPS Utilization per Node resource of the {{
        $labels.type }} service ({{ $labels.stage }} stage) has a saturation exceeding
        SLO and is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Disk Sustained Write IOPS Utilization per Node resource:

        Gitaly runs on Google Cloud's Persistent Disk product. This has a published sustained maximum write IOPS value. This value can be exceeded for brief periods.

        If a single node is consistently reaching saturation, it may indicate a noisy-neighbour repository, possible abuse or it may indicate that the node needs rebalancing.

        More information can be found at https://cloud.google.com/compute/docs/disks/performance.
      grafana_dashboard_id: alerts-sat_disk_sus_write_iops
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_disk_sus_write_iops?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_datasource_id: mimir-gitlab-gstg
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1520756669"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(device,environment,fqdn,shard,stage,tier,type) (
          clamp_min(
            clamp_max(
              rate(node_disk_writes_completed_total{device!="sda", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[20m])
              /
              node_disk_max_write_iops{device!="sda", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              ,
              1)
          ,
          0)
        )
      promql_template_1: |
        max by(device,environment,fqdn,shard,stage,tier,type) (
          clamp_min(
            clamp_max(
              rate(node_disk_writes_completed_total{device!="sda", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[20m])
              /
              node_disk_max_write_iops{device!="sda", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s3
    expr: |
      gitlab_component_saturation:ratio{component="disk_sustained_write_iops",env="gstg",type="gitaly"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="disk_sustained_write_iops"}
  - alert: component_saturation_slo_out_of_bounds:disk_sustained_write_throughput
    for: 25m
    annotations:
      title: The Disk Sustained Write Throughput Utilization per Node resource of
        the {{ $labels.type }} service ({{ $labels.stage }} stage) has a saturation
        exceeding SLO and is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Disk Sustained Write Throughput Utilization per Node resource:

        Gitaly runs on Google Cloud's Persistent Disk product. This has a published sustained maximum write throughput value. This value can be exceeded for brief periods.

        If a single node is consistently reaching saturation, it may indicate a noisy-neighbour repository, possible abuse or it may indicate that the node needs rebalancing.

        More information can be found at https://cloud.google.com/compute/docs/disks/performance.
      grafana_dashboard_id: alerts-sat_disk_sus_write_throughput
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_disk_sus_write_throughput?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_datasource_id: mimir-gitlab-gstg
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "374696527"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(device,environment,fqdn,shard,stage,tier,type) (
          clamp_min(
            clamp_max(
              rate(node_disk_written_bytes_total{device!="sda", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[20m])
              /
              node_disk_max_write_bytes_seconds{device!="sda", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              ,
              1)
          ,
          0)
        )
      promql_template_1: |
        max by(device,environment,fqdn,shard,stage,tier,type) (
          clamp_min(
            clamp_max(
              rate(node_disk_written_bytes_total{device!="sda", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[20m])
              /
              node_disk_max_write_bytes_seconds{device!="sda", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s3
    expr: |
      gitlab_component_saturation:ratio{component="disk_sustained_write_throughput",env="gstg",type="gitaly"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="disk_sustained_write_throughput"}
  - alert: component_saturation_slo_out_of_bounds:gitaly_active_node_available_space
    for: 5m
    annotations:
      title: The Gitaly Active Node Available Space resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage) has a saturation exceeding SLO and
        is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Gitaly Active Node Available Space resource:

        Available space on active gitaly nodes

        Active nodes are Gitaly nodes that are currently receiving new repositories

        We allow new Gitaly nodes to receive traffic until their disk is about 75% full. After which we mark the weight of the node as 0 in the [Gitaly shard weights assigner](https://gitlab.com/gitlab-com/gl-infra/gitaly-shard-weights-assigner/-/blob/master/assigner.rb#L9).

        To make sure we always have enough shards receiving new repositories, we want to have at least 8% of the total storage to be available for new projects. When this resource gets saturated, we could be creating to many projects on a limited set of nodes, which could cause these nodes to be busier than usual. To add new nodes start a new change issue with `/change declare` in Slack, and select the `change_gitaly_storage_creation.md` template.
      grafana_dashboard_id: alerts-sat_gitaly_active_available_space
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_gitaly_active_available_space?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_datasource_id: mimir-gitlab-gstg
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "3803311012"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment,shard,stage,tier,type) (
          clamp_min(
            clamp_max(
              1 - (
                sum by (environment,shard,stage,tier,type) (
                  (
                    node_filesystem_avail_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}", fqdn=~"gitaly-.*-stor-.*",mountpoint="/var/opt/gitlab",shard=~"default"} -
                    (node_filesystem_size_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}", fqdn=~"gitaly-.*-stor-.*",mountpoint="/var/opt/gitlab",shard=~"default"} * 0.20)
                  )
                  and
                  (instance:node_filesystem_avail:ratio{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}", fqdn=~"gitaly-.*-stor-.*",mountpoint="/var/opt/gitlab",shard=~"default"} > 0.20)
                )
                /
                sum by (environment,shard,stage,tier,type)(
                  node_filesystem_size_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}", fqdn=~"gitaly-.*-stor-.*",mountpoint="/var/opt/gitlab",shard=~"default"}
                )
              )
              ,
              1)
          ,
          0)
        )
      promql_template_1: |
        max by(environment,shard,stage,tier,type) (
          clamp_min(
            clamp_max(
              1 - (
                sum by (environment,shard,stage,tier,type) (
                  (
                    node_filesystem_avail_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}", fqdn=~"gitaly-.*-stor-.*",mountpoint="/var/opt/gitlab",shard=~"default"} -
                    (node_filesystem_size_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}", fqdn=~"gitaly-.*-stor-.*",mountpoint="/var/opt/gitlab",shard=~"default"} * 0.20)
                  )
                  and
                  (instance:node_filesystem_avail:ratio{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}", fqdn=~"gitaly-.*-stor-.*",mountpoint="/var/opt/gitlab",shard=~"default"} > 0.20)
                )
                /
                sum by (environment,shard,stage,tier,type)(
                  node_filesystem_size_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}", fqdn=~"gitaly-.*-stor-.*",mountpoint="/var/opt/gitlab",shard=~"default"}
                )
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/gitaly/gitalyctl.md#stopping-migration-during-emergency
    labels:
      alert_type: cause
      pager: pagerduty
      rules_domain: general
      severity: s2
    expr: |
      gitlab_component_saturation:ratio{component="gitaly_active_node_available_space",env="gstg",type="gitaly"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="gitaly_active_node_available_space"}
  - alert: component_saturation_slo_out_of_bounds:gitaly_total_disk_space
    for: 5m
    annotations:
      title: The Gitaly Total Disk Utilization resource of the {{ $labels.type }}
        service ({{ $labels.stage }} stage) has a saturation exceeding SLO and is
        close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Gitaly Total Disk Utilization resource:

        Gitaly Total Disk Utilization.

        This saturation metric monitors the total available capacity across the entire Gitaly fleet. By ensuring that we keep sufficient headroom on the saturation resource, we are able to spread load across the fleet.

        When this alert fires, consider adding new Gitaly nodes. The [Gitaly Capacity Planner](https://dashboards.gitlab.net/d/alerts-gitaly_capacity_planner/alerts-gitaly-capacity-planner?orgId=1) dashboard can help determine how many new nodes will be needed.
      grafana_dashboard_id: alerts-sat_gitaly_total_disk_space
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_gitaly_total_disk_space?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_datasource_id: mimir-gitlab-gstg
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "998219612"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment,shard,stage,tier,type) (
          clamp_min(
            clamp_max(
              1 - (
                sum by (environment,shard,stage,tier,type) (
                  node_filesystem_avail_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}", mountpoint="/var/opt/gitlab"}
                )
                /
                sum by (environment,shard,stage,tier,type) (
                  node_filesystem_size_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}", mountpoint="/var/opt/gitlab"}
                )
              )
              ,
              1)
          ,
          0)
        )
      promql_template_1: |
        max by(environment,shard,stage,tier,type) (
          clamp_min(
            clamp_max(
              1 - (
                sum by (environment,shard,stage,tier,type) (
                  node_filesystem_avail_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}", mountpoint="/var/opt/gitlab"}
                )
                /
                sum by (environment,shard,stage,tier,type) (
                  node_filesystem_size_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}", mountpoint="/var/opt/gitlab"}
                )
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s3
    expr: |
      gitlab_component_saturation:ratio{component="gitaly_total_disk_space",env="gstg",type="gitaly"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="gitaly_total_disk_space"}
  - alert: component_saturation_slo_out_of_bounds:go_goroutines
    for: 5m
    annotations:
      title: The Go goroutines Utilization per Node resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage) has a saturation exceeding SLO and
        is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Go goroutines Utilization per Node resource:

        Go goroutines utilization per node.

        Goroutines leaks can cause memory saturation which can cause service degradation.

        A limit of 250k goroutines is very generous, so if a service exceeds this limit, it's a sign of a leak and it should be dealt with.
      grafana_dashboard_id: alerts-sat_go_goroutines
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_go_goroutines?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_datasource_id: mimir-gitlab-gstg
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "3712788301"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(env,environment,fqdn,instance,region,shard,stage,tier,type) (
          clamp_min(
            clamp_max(
              sum by (env,environment,fqdn,instance,region,shard,stage,tier,type) (
                go_goroutines{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              )
              /
              250000
              ,
              1)
          ,
          0)
        )
      promql_template_1: |
        max by(env,environment,fqdn,instance,region,shard,stage,tier,type) (
          clamp_min(
            clamp_max(
              sum by (env,environment,fqdn,instance,region,shard,stage,tier,type) (
                go_goroutines{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              )
              /
              250000
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      pager: pagerduty
      rules_domain: general
      severity: s2
    expr: |
      gitlab_component_saturation:ratio{component="go_goroutines",env="gstg",type="gitaly"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="go_goroutines"}
  - alert: component_saturation_slo_out_of_bounds:go_memory
    for: 5m
    annotations:
      title: The Go Memory Utilization per Node resource of the {{ $labels.type }}
        service ({{ $labels.stage }} stage) has a saturation exceeding SLO and is
        close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Go Memory Utilization per Node resource:

        Go's memory allocation strategy can make it look like a Go process is saturating memory when measured using RSS, when in fact the process is not at risk of memory saturation. For this reason, we measure Go processes using the `go_memstat_alloc_bytes`
      grafana_dashboard_id: alerts-sat_go_memory
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_go_memory?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_datasource_id: mimir-gitlab-gstg
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "3631721613"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(env,environment,fqdn,shard,stage,tier,type) (
          clamp_min(
            clamp_max(
              max by (env,environment,fqdn,shard,stage,tier,type) (
                go_memstats_alloc_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              )
              /
              sum by (env,environment,fqdn,shard,stage,tier,type) (
                node_memory_MemTotal_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              )
              ,
              1)
          ,
          0)
        )
      promql_template_1: |
        max by(env,environment,fqdn,shard,stage,tier,type) (
          clamp_min(
            clamp_max(
              max by (env,environment,fqdn,shard,stage,tier,type) (
                go_memstats_alloc_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              )
              /
              sum by (env,environment,fqdn,shard,stage,tier,type) (
                node_memory_MemTotal_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
    expr: |
      gitlab_component_saturation:ratio{component="go_memory",env="gstg",type="gitaly"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="go_memory"}
  - alert: component_saturation_slo_out_of_bounds:memory
    for: 5m
    annotations:
      title: The Memory Utilization per Node resource of the {{ $labels.type }} service
        ({{ $labels.stage }} stage) has a saturation exceeding SLO and is close to
        its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Memory Utilization per Node resource:

        Memory utilization per device per node.
      grafana_dashboard_id: alerts-sat_memory
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_memory?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_datasource_id: mimir-gitlab-gstg
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1955556769"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment,fqdn,shard,stage,tier,type) (
          clamp_min(
            clamp_max(
              instance:node_memory_utilization:ratio{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"} or instance:node_memory_utilisation:ratio{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              ,
              1)
          ,
          0)
        )
      promql_template_1: |
        max by(environment,fqdn,shard,stage,tier,type) (
          clamp_min(
            clamp_max(
              instance:node_memory_utilization:ratio{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"} or instance:node_memory_utilisation:ratio{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
    expr: |
      gitlab_component_saturation:ratio{component="memory",env="gstg",type="gitaly"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="memory"}
  - alert: component_saturation_slo_out_of_bounds:nf_conntrack_entries
    for: 5m
    annotations:
      title: The conntrack Entries per Node resource of the {{ $labels.type }} service
        ({{ $labels.stage }} stage) has a saturation exceeding SLO and is close to
        its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the conntrack Entries per Node resource:

        Netfilter connection tracking table utilization per node.

        When saturated, new connection attempts (incoming SYN packets) are dropped with no reply, leaving clients to slowly retry (and typically fail again) over the next several seconds.  When packets are being dropped due to this condition, kernel will log the event as: "nf_conntrack: table full, dropping packet".
      grafana_dashboard_id: alerts-sat_conntrack
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_conntrack?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_datasource_id: mimir-gitlab-gstg
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "503581002"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment,fqdn,instance,shard,stage,tier,type) (
          clamp_min(
            clamp_max(
              max_over_time(node_nf_conntrack_entries{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[1m])
              /
              node_nf_conntrack_entries_limit{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              ,
              1)
          ,
          0)
        )
      promql_template_1: |
        max by(environment,fqdn,instance,shard,stage,tier,type) (
          clamp_min(
            clamp_max(
              max_over_time(node_nf_conntrack_entries{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[1m])
              /
              node_nf_conntrack_entries_limit{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s3
    expr: |
      gitlab_component_saturation:ratio{component="nf_conntrack_entries",env="gstg",type="gitaly"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="nf_conntrack_entries"}
  - alert: component_saturation_slo_out_of_bounds:node_schedstat_waiting
    for: 90m
    annotations:
      title: The Node Scheduler Waiting Time resource of the {{ $labels.type }} service
        ({{ $labels.stage }} stage) has a saturation exceeding SLO and is close to
        its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Node Scheduler Waiting Time resource:

        Measures the amount of scheduler waiting time that processes are waiting to be scheduled, according to [`CPU Scheduling Metrics`](https://www.robustperception.io/cpu-scheduling-metrics-from-the-node-exporter).

        A high value indicates that a node has more processes to be run than CPU time available to handle them, and may lead to degraded responsiveness and performance from the application.

        Additionally, it may indicate that the fleet is under-provisioned.
      grafana_dashboard_id: alerts-sat_node_schedstat_waiting
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_node_schedstat_waiting?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_datasource_id: mimir-gitlab-gstg
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1415313189"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment,fqdn,shard,stage,tier,type) (
          clamp_min(
            clamp_max(
              avg without (cpu) (rate(node_schedstat_waiting_seconds_total{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[1h]))
              ,
              1)
          ,
          0)
        )
      promql_template_1: |
        max by(environment,fqdn,shard,stage,tier,type) (
          clamp_min(
            clamp_max(
              avg without (cpu) (rate(node_schedstat_waiting_seconds_total{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[1h]))
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
    expr: |
      gitlab_component_saturation:ratio{component="node_schedstat_waiting",env="gstg",type="gitaly"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="node_schedstat_waiting"}
  - alert: component_saturation_slo_out_of_bounds:open_fds
    for: 5m
    annotations:
      title: The Open file descriptor utilization per instance resource of the {{
        $labels.type }} service ({{ $labels.stage }} stage) has a saturation exceeding
        SLO and is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Open file descriptor utilization per instance resource:

        Open file descriptor utilization per instance.

        Saturation on file descriptor limits may indicate a resource-descriptor leak in the application.

        As a temporary fix, you may want to consider restarting the affected process.
      grafana_dashboard_id: alerts-sat_open_fds
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_open_fds?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_datasource_id: mimir-gitlab-gstg
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1001792825"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment,instance,job,shard,stage,tier,type) (
          clamp_min(
            clamp_max(
              (
                process_open_fds{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
                /
                process_max_fds{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              )
              or
              (
                ruby_file_descriptors{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
                /
                ruby_process_max_fds{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              )
              ,
              1)
          ,
          0)
        )
      promql_template_1: |
        max by(environment,instance,job,shard,stage,tier,type) (
          clamp_min(
            clamp_max(
              (
                process_open_fds{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
                /
                process_max_fds{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              )
              or
              (
                ruby_file_descriptors{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
                /
                ruby_process_max_fds{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      pager: pagerduty
      rules_domain: general
      severity: s2
    expr: |
      gitlab_component_saturation:ratio{component="open_fds",env="gstg",type="gitaly"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="open_fds"}
  - alert: component_saturation_slo_out_of_bounds:single_node_cpu
    for: 10m
    annotations:
      title: The Average CPU Utilization per Node resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage) has a saturation exceeding SLO and
        is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Average CPU Utilization per Node resource:

        Average CPU utilization per Node.

        If average CPU is saturated, it may indicate that a fleet is in need to horizontal or vertical scaling. It may also indicate imbalances in load in a fleet.
      grafana_dashboard_id: alerts-sat_single_node_cpu
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_single_node_cpu?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_datasource_id: mimir-gitlab-gstg
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "3372411356"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment,fqdn,shard,stage,tier,type) (
          clamp_min(
            clamp_max(
              avg without(cpu, mode) (1 - rate(node_cpu_seconds_total{mode="idle", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m]))
              ,
              1)
          ,
          0)
        )
      promql_template_1: |
        max by(environment,fqdn,shard,stage,tier,type) (
          clamp_min(
            clamp_max(
              avg without(cpu, mode) (1 - rate(node_cpu_seconds_total{mode="idle", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m]))
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
    expr: |
      gitlab_component_saturation:ratio{component="single_node_cpu",env="gstg",type="gitaly"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="single_node_cpu"}
