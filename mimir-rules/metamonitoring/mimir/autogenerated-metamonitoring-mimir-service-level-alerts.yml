# WARNING. DO NOT EDIT THIS FILE BY HAND. USE ./mimir-rules-jsonnet/service-component-alerts.jsonnet TO GENERATE IT
# YOUR CHANGES WILL BE OVERRIDDEN
groups:
- name: 'Service Component Alerts: mimir'
  interval: 1m
  rules:
  - alert: MimirServiceMimirCompactorErrorSLOViolation
    for: 2m
    annotations:
      title: The mimir_compactor SLI of the mimir service (`{{ $labels.stage }}` stage)
        has an error rate violating SLO
      description: |
        The compactor increases query performance and reduces long-term storage usage by combining blocks. This SLI monitors the compactor operations for failures.

        Currently the error-rate is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: mimir-main/mimir-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/mimir-main/mimir-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_datasource_id: mimir-metamonitoring
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "3914025672"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(cortex_compactor_group_compactions_failures_total{environment="{{ $labels.environment }}",job="mimir/compactor",namespace="mimir",stage="{{ $labels.stage }}",type="mimir"}[5m])
        )
      runbook: docs/mimir/README.md
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      rules_domain: general
      severity: s3
      sli_type: error
      slo_alert: "yes"
      team: observability
      user_impacting: "no"
      window: 1h
    expr: |
      (
        (
          gitlab_component_errors:ratio_1h{component="mimir_compactor",monitor="global",type="mimir"}
          > (14.4 * 0.050000)
        )
        and on (env,environment,tier,type,stage,component)
        (
          gitlab_component_errors:ratio_5m{component="mimir_compactor",monitor="global",type="mimir"}
          > (14.4 * 0.050000)
        )
      )
      and on(env,environment,tier,type,stage,component)
      (
        sum by(env,environment,tier,type,stage,component) (gitlab_component_ops:rate_1h{component="mimir_compactor",monitor="global",type="mimir"}) >= 1
      )
  - alert: MimirServiceMimirCompactorErrorSLOViolation
    for: 2m
    annotations:
      title: The mimir_compactor SLI of the mimir service (`{{ $labels.stage }}` stage)
        has an error rate violating SLO
      description: |
        The compactor increases query performance and reduces long-term storage usage by combining blocks. This SLI monitors the compactor operations for failures.

        Currently the error-rate is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: mimir-main/mimir-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/mimir-main/mimir-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_datasource_id: mimir-metamonitoring
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "3914025672"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(cortex_compactor_group_compactions_failures_total{environment="{{ $labels.environment }}",job="mimir/compactor",namespace="mimir",stage="{{ $labels.stage }}",type="mimir"}[5m])
        )
      runbook: docs/mimir/README.md
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      rules_domain: general
      severity: s3
      sli_type: error
      slo_alert: "yes"
      team: observability
      user_impacting: "no"
      window: 6h
    expr: |
      (
        (
          gitlab_component_errors:ratio_6h{component="mimir_compactor",monitor="global",type="mimir"}
          > (6 * 0.050000)
        )
        and on (env,environment,tier,type,stage,component)
        (
          gitlab_component_errors:ratio_30m{component="mimir_compactor",monitor="global",type="mimir"}
          > (6 * 0.050000)
        )
      )
      and on(env,environment,tier,type,stage,component)
      (
        sum by(env,environment,tier,type,stage,component) (gitlab_component_ops:rate_6h{component="mimir_compactor",monitor="global",type="mimir"}) >= 0.16667
      )
  - alert: MimirServiceMimirCompactorTrafficCessation
    for: 5m
    annotations:
      title: The mimir_compactor SLI of the mimir service (`{{ $labels.stage }}` stage)
        has not received any traffic in the past 30m
      description: |
        The compactor increases query performance and reduces long-term storage usage by combining blocks. This SLI monitors the compactor operations for failures.

        This alert signifies that the SLI is reporting a cessation of traffic; the signal is present, but is zero.
      grafana_dashboard_id: mimir-main/mimir-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/mimir-main/mimir-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_datasource_id: mimir-metamonitoring
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2690126094"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(cortex_compactor_group_compaction_runs_started_total{environment="{{ $labels.environment }}",job="mimir/compactor",namespace="mimir",stage="{{ $labels.stage }}",type="mimir"}[5m])
        )
      runbook: docs/mimir/README.md
    labels:
      aggregation: component
      alert_class: traffic_cessation
      alert_type: cause
      feature_category: not_owned
      rules_domain: general
      severity: s3
      sli_type: ops
      slo_alert: "no"
      team: observability
      user_impacting: "no"
    expr: |
      gitlab_component_ops:rate_30m{component="mimir_compactor",monitor="global",stage="main",type="mimir"} == 0
      and
      gitlab_component_ops:rate_30m{component="mimir_compactor",monitor="global",stage="main",type="mimir"} offset 1h >= 0.16666666666666666
  - alert: MimirServiceMimirCompactorTrafficAbsent
    for: 30m
    annotations:
      title: The mimir_compactor SLI of the mimir service (`{{ $labels.stage }}` stage)
        has not reported any traffic in the past 30m
      description: |
        The compactor increases query performance and reduces long-term storage usage by combining blocks. This SLI monitors the compactor operations for failures.

        This alert signifies that the SLI was previously reporting traffic, but is no longer - the signal is absent.

        This could be caused by a change to the metrics used in the SLI, or by the service not receiving traffic.
      grafana_dashboard_id: mimir-main/mimir-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/mimir-main/mimir-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_datasource_id: mimir-metamonitoring
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2690126094"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(cortex_compactor_group_compaction_runs_started_total{environment="{{ $labels.environment }}",job="mimir/compactor",namespace="mimir",stage="{{ $labels.stage }}",type="mimir"}[5m])
        )
      runbook: docs/mimir/README.md
    labels:
      aggregation: component
      alert_class: traffic_cessation
      alert_type: cause
      feature_category: not_owned
      rules_domain: general
      severity: s3
      sli_type: ops
      slo_alert: "no"
      team: observability
      user_impacting: "no"
    expr: |
      gitlab_component_ops:rate_5m{component="mimir_compactor",monitor="global",stage="main",type="mimir"} offset 1h
      unless
      gitlab_component_ops:rate_5m{component="mimir_compactor",monitor="global",stage="main",type="mimir"}
  - alert: MimirServiceMimirDistributorApdexSLOViolation
    for: 2m
    annotations:
      title: The mimir_distributor SLI of the mimir service (`{{ $labels.stage }}`
        stage) has an apdex violating SLO
      description: |
        The distributor is a stateless component that receives time-series data from remote-write requests via Prometheus or the Grafana agent. It validates the data for correctness and ensures that it is within the configured limits for a given tenant. The distributor then divides the data into batches and sends it to multiple ingesters in parallel, shards the series among ingesters, and replicates each series by the configured replication factor. By default, the configured replication factor is three. This SLI monitors the distributor requests. 5xx responses are considered failures.

        Currently the apdex value is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: mimir-main/mimir-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/mimir-main/mimir-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_datasource_id: mimir-metamonitoring
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "158496538"
      grafana_variables: environment,stage
      promql_template_1: |
        histogram_quantile(
          0.950000,
          sum by (env,environment,tier,stage,le) (
            rate(cortex_request_duration_seconds_bucket{environment="{{ $labels.environment }}",job="mimir/distributor",namespace="mimir",route=~"/distributor\\.Distributor/Push|/httpgrpc.*|(api_(v1|prom)_push)|otlp_v1_metrics",stage="{{ $labels.stage }}",type="mimir"}[5m])
          )
        )
      runbook: docs/mimir/README.md
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: apdex
      slo_alert: "yes"
      team: observability
      user_impacting: "no"
      window: 1h
    expr: |
      (
        (
          gitlab_component_apdex:ratio_1h{component="mimir_distributor",monitor="global",type="mimir"}
          < (1 - 14.4 * 0.050000)
        )
        and on (env,environment,tier,type,stage,component)
        (
          gitlab_component_apdex:ratio_5m{component="mimir_distributor",monitor="global",type="mimir"}
          < (1 - 14.4 * 0.050000)
        )
      )
      and on(env,environment,tier,type,stage,component)
      (
        sum by(env,environment,tier,type,stage,component) (gitlab_component_ops:rate_1h{component="mimir_distributor",monitor="global",type="mimir"}) >= 1
      )
  - alert: MimirServiceMimirDistributorApdexSLOViolation
    for: 2m
    annotations:
      title: The mimir_distributor SLI of the mimir service (`{{ $labels.stage }}`
        stage) has an apdex violating SLO
      description: |
        The distributor is a stateless component that receives time-series data from remote-write requests via Prometheus or the Grafana agent. It validates the data for correctness and ensures that it is within the configured limits for a given tenant. The distributor then divides the data into batches and sends it to multiple ingesters in parallel, shards the series among ingesters, and replicates each series by the configured replication factor. By default, the configured replication factor is three. This SLI monitors the distributor requests. 5xx responses are considered failures.

        Currently the apdex value is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: mimir-main/mimir-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/mimir-main/mimir-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_datasource_id: mimir-metamonitoring
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "158496538"
      grafana_variables: environment,stage
      promql_template_1: |
        histogram_quantile(
          0.950000,
          sum by (env,environment,tier,stage,le) (
            rate(cortex_request_duration_seconds_bucket{environment="{{ $labels.environment }}",job="mimir/distributor",namespace="mimir",route=~"/distributor\\.Distributor/Push|/httpgrpc.*|(api_(v1|prom)_push)|otlp_v1_metrics",stage="{{ $labels.stage }}",type="mimir"}[5m])
          )
        )
      runbook: docs/mimir/README.md
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: apdex
      slo_alert: "yes"
      team: observability
      user_impacting: "no"
      window: 6h
    expr: |
      (
        (
          gitlab_component_apdex:ratio_6h{component="mimir_distributor",monitor="global",type="mimir"}
          < (1 - 6 * 0.050000)
        )
        and on (env,environment,tier,type,stage,component)
        (
          gitlab_component_apdex:ratio_30m{component="mimir_distributor",monitor="global",type="mimir"}
          < (1 - 6 * 0.050000)
        )
      )
      and on(env,environment,tier,type,stage,component)
      (
        sum by(env,environment,tier,type,stage,component) (gitlab_component_ops:rate_6h{component="mimir_distributor",monitor="global",type="mimir"}) >= 0.16667
      )
  - alert: MimirServiceMimirDistributorErrorSLOViolation
    for: 2m
    annotations:
      title: The mimir_distributor SLI of the mimir service (`{{ $labels.stage }}`
        stage) has an error rate violating SLO
      description: |
        The distributor is a stateless component that receives time-series data from remote-write requests via Prometheus or the Grafana agent. It validates the data for correctness and ensures that it is within the configured limits for a given tenant. The distributor then divides the data into batches and sends it to multiple ingesters in parallel, shards the series among ingesters, and replicates each series by the configured replication factor. By default, the configured replication factor is three. This SLI monitors the distributor requests. 5xx responses are considered failures.

        Currently the error-rate is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: mimir-main/mimir-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/mimir-main/mimir-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_datasource_id: mimir-metamonitoring
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "3489613837"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(cortex_request_duration_seconds_count{environment="{{ $labels.environment }}",job="mimir/distributor",namespace="mimir",route=~"/distributor\\.Distributor/Push|/httpgrpc.*|(api_(v1|prom)_push)|otlp_v1_metrics",stage="{{ $labels.stage }}",status_code=~"^5.*",type="mimir"}[5m])
        )
      runbook: docs/mimir/README.md
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: error
      slo_alert: "yes"
      team: observability
      user_impacting: "no"
      window: 1h
    expr: |
      (
        (
          gitlab_component_errors:ratio_1h{component="mimir_distributor",monitor="global",type="mimir"}
          > (14.4 * 0.050000)
        )
        and on (env,environment,tier,type,stage,component)
        (
          gitlab_component_errors:ratio_5m{component="mimir_distributor",monitor="global",type="mimir"}
          > (14.4 * 0.050000)
        )
      )
      and on(env,environment,tier,type,stage,component)
      (
        sum by(env,environment,tier,type,stage,component) (gitlab_component_ops:rate_1h{component="mimir_distributor",monitor="global",type="mimir"}) >= 1
      )
  - alert: MimirServiceMimirDistributorErrorSLOViolation
    for: 2m
    annotations:
      title: The mimir_distributor SLI of the mimir service (`{{ $labels.stage }}`
        stage) has an error rate violating SLO
      description: |
        The distributor is a stateless component that receives time-series data from remote-write requests via Prometheus or the Grafana agent. It validates the data for correctness and ensures that it is within the configured limits for a given tenant. The distributor then divides the data into batches and sends it to multiple ingesters in parallel, shards the series among ingesters, and replicates each series by the configured replication factor. By default, the configured replication factor is three. This SLI monitors the distributor requests. 5xx responses are considered failures.

        Currently the error-rate is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: mimir-main/mimir-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/mimir-main/mimir-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_datasource_id: mimir-metamonitoring
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "3489613837"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(cortex_request_duration_seconds_count{environment="{{ $labels.environment }}",job="mimir/distributor",namespace="mimir",route=~"/distributor\\.Distributor/Push|/httpgrpc.*|(api_(v1|prom)_push)|otlp_v1_metrics",stage="{{ $labels.stage }}",status_code=~"^5.*",type="mimir"}[5m])
        )
      runbook: docs/mimir/README.md
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: error
      slo_alert: "yes"
      team: observability
      user_impacting: "no"
      window: 6h
    expr: |
      (
        (
          gitlab_component_errors:ratio_6h{component="mimir_distributor",monitor="global",type="mimir"}
          > (6 * 0.050000)
        )
        and on (env,environment,tier,type,stage,component)
        (
          gitlab_component_errors:ratio_30m{component="mimir_distributor",monitor="global",type="mimir"}
          > (6 * 0.050000)
        )
      )
      and on(env,environment,tier,type,stage,component)
      (
        sum by(env,environment,tier,type,stage,component) (gitlab_component_ops:rate_6h{component="mimir_distributor",monitor="global",type="mimir"}) >= 0.16667
      )
  - alert: MimirServiceMimirDistributorTrafficCessation
    for: 5m
    annotations:
      title: The mimir_distributor SLI of the mimir service (`{{ $labels.stage }}`
        stage) has not received any traffic in the past 30m
      description: |
        The distributor is a stateless component that receives time-series data from remote-write requests via Prometheus or the Grafana agent. It validates the data for correctness and ensures that it is within the configured limits for a given tenant. The distributor then divides the data into batches and sends it to multiple ingesters in parallel, shards the series among ingesters, and replicates each series by the configured replication factor. By default, the configured replication factor is three. This SLI monitors the distributor requests. 5xx responses are considered failures.

        This alert signifies that the SLI is reporting a cessation of traffic; the signal is present, but is zero.
      grafana_dashboard_id: mimir-main/mimir-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/mimir-main/mimir-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_datasource_id: mimir-metamonitoring
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "4071572192"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(cortex_request_duration_seconds_count{environment="{{ $labels.environment }}",job="mimir/distributor",namespace="mimir",route=~"/distributor\\.Distributor/Push|/httpgrpc.*|(api_(v1|prom)_push)|otlp_v1_metrics",stage="{{ $labels.stage }}",type="mimir"}[5m])
        )
      runbook: docs/mimir/README.md
    labels:
      aggregation: component
      alert_class: traffic_cessation
      alert_type: cause
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: ops
      slo_alert: "no"
      team: observability
      user_impacting: "no"
    expr: |
      gitlab_component_ops:rate_30m{component="mimir_distributor",monitor="global",stage="main",type="mimir"} == 0
      and
      gitlab_component_ops:rate_30m{component="mimir_distributor",monitor="global",stage="main",type="mimir"} offset 1h >= 0.16666666666666666
  - alert: MimirServiceMimirDistributorTrafficAbsent
    for: 30m
    annotations:
      title: The mimir_distributor SLI of the mimir service (`{{ $labels.stage }}`
        stage) has not reported any traffic in the past 30m
      description: |
        The distributor is a stateless component that receives time-series data from remote-write requests via Prometheus or the Grafana agent. It validates the data for correctness and ensures that it is within the configured limits for a given tenant. The distributor then divides the data into batches and sends it to multiple ingesters in parallel, shards the series among ingesters, and replicates each series by the configured replication factor. By default, the configured replication factor is three. This SLI monitors the distributor requests. 5xx responses are considered failures.

        This alert signifies that the SLI was previously reporting traffic, but is no longer - the signal is absent.

        This could be caused by a change to the metrics used in the SLI, or by the service not receiving traffic.
      grafana_dashboard_id: mimir-main/mimir-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/mimir-main/mimir-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_datasource_id: mimir-metamonitoring
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "4071572192"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(cortex_request_duration_seconds_count{environment="{{ $labels.environment }}",job="mimir/distributor",namespace="mimir",route=~"/distributor\\.Distributor/Push|/httpgrpc.*|(api_(v1|prom)_push)|otlp_v1_metrics",stage="{{ $labels.stage }}",type="mimir"}[5m])
        )
      runbook: docs/mimir/README.md
    labels:
      aggregation: component
      alert_class: traffic_cessation
      alert_type: cause
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: ops
      slo_alert: "no"
      team: observability
      user_impacting: "no"
    expr: |
      gitlab_component_ops:rate_5m{component="mimir_distributor",monitor="global",stage="main",type="mimir"} offset 1h
      unless
      gitlab_component_ops:rate_5m{component="mimir_distributor",monitor="global",stage="main",type="mimir"}
  - alert: MimirServiceMimirIngesterApdexSLOViolation
    for: 2m
    annotations:
      title: The mimir_ingester SLI of the mimir service (`{{ $labels.stage }}` stage)
        has an apdex violating SLO
      description: |
        The ingester is a stateful component that writes incoming series to long-term storage on the write path and returns series samples for queries on the read path. Incoming time series data from distributors are temporarily stored in the ingester’s memory or offloaded to disk before being written to long-term storage. Eventually, all series are written to disk and periodically uploaded (by default every two hours) to the long-term storage. This SLI monitors the distributor requests. 5xx responses are considered failures.

        Currently the apdex value is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: mimir-main/mimir-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/mimir-main/mimir-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_datasource_id: mimir-metamonitoring
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "93090418"
      grafana_variables: environment,stage
      promql_template_1: |
        histogram_quantile(
          0.950000,
          sum by (env,environment,tier,stage,le) (
            rate(cortex_request_duration_seconds_bucket{environment="{{ $labels.environment }}",job="mimir/ingester",namespace="mimir",route="/cortex.Ingester/Push",stage="{{ $labels.stage }}",type="mimir"}[5m])
          )
        )
      runbook: docs/mimir/README.md
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: apdex
      slo_alert: "yes"
      team: observability
      user_impacting: "no"
      window: 1h
    expr: |
      (
        (
          gitlab_component_apdex:ratio_1h{component="mimir_ingester",monitor="global",type="mimir"}
          < (1 - 14.4 * 0.050000)
        )
        and on (env,environment,tier,type,stage,component)
        (
          gitlab_component_apdex:ratio_5m{component="mimir_ingester",monitor="global",type="mimir"}
          < (1 - 14.4 * 0.050000)
        )
      )
      and on(env,environment,tier,type,stage,component)
      (
        sum by(env,environment,tier,type,stage,component) (gitlab_component_ops:rate_1h{component="mimir_ingester",monitor="global",type="mimir"}) >= 1
      )
  - alert: MimirServiceMimirIngesterApdexSLOViolation
    for: 2m
    annotations:
      title: The mimir_ingester SLI of the mimir service (`{{ $labels.stage }}` stage)
        has an apdex violating SLO
      description: |
        The ingester is a stateful component that writes incoming series to long-term storage on the write path and returns series samples for queries on the read path. Incoming time series data from distributors are temporarily stored in the ingester’s memory or offloaded to disk before being written to long-term storage. Eventually, all series are written to disk and periodically uploaded (by default every two hours) to the long-term storage. This SLI monitors the distributor requests. 5xx responses are considered failures.

        Currently the apdex value is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: mimir-main/mimir-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/mimir-main/mimir-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_datasource_id: mimir-metamonitoring
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "93090418"
      grafana_variables: environment,stage
      promql_template_1: |
        histogram_quantile(
          0.950000,
          sum by (env,environment,tier,stage,le) (
            rate(cortex_request_duration_seconds_bucket{environment="{{ $labels.environment }}",job="mimir/ingester",namespace="mimir",route="/cortex.Ingester/Push",stage="{{ $labels.stage }}",type="mimir"}[5m])
          )
        )
      runbook: docs/mimir/README.md
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: apdex
      slo_alert: "yes"
      team: observability
      user_impacting: "no"
      window: 6h
    expr: |
      (
        (
          gitlab_component_apdex:ratio_6h{component="mimir_ingester",monitor="global",type="mimir"}
          < (1 - 6 * 0.050000)
        )
        and on (env,environment,tier,type,stage,component)
        (
          gitlab_component_apdex:ratio_30m{component="mimir_ingester",monitor="global",type="mimir"}
          < (1 - 6 * 0.050000)
        )
      )
      and on(env,environment,tier,type,stage,component)
      (
        sum by(env,environment,tier,type,stage,component) (gitlab_component_ops:rate_6h{component="mimir_ingester",monitor="global",type="mimir"}) >= 0.16667
      )
  - alert: MimirServiceMimirIngesterErrorSLOViolation
    for: 2m
    annotations:
      title: The mimir_ingester SLI of the mimir service (`{{ $labels.stage }}` stage)
        has an error rate violating SLO
      description: |
        The ingester is a stateful component that writes incoming series to long-term storage on the write path and returns series samples for queries on the read path. Incoming time series data from distributors are temporarily stored in the ingester’s memory or offloaded to disk before being written to long-term storage. Eventually, all series are written to disk and periodically uploaded (by default every two hours) to the long-term storage. This SLI monitors the distributor requests. 5xx responses are considered failures.

        Currently the error-rate is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: mimir-main/mimir-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/mimir-main/mimir-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_datasource_id: mimir-metamonitoring
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "3162729023"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(cortex_request_duration_seconds_count{environment="{{ $labels.environment }}",job="mimir/ingester",namespace="mimir",route="/cortex.Ingester/Push",stage="{{ $labels.stage }}",status_code=~"^5.*",type="mimir"}[5m])
        )
      runbook: docs/mimir/README.md
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: error
      slo_alert: "yes"
      team: observability
      user_impacting: "no"
      window: 1h
    expr: |
      (
        (
          gitlab_component_errors:ratio_1h{component="mimir_ingester",monitor="global",type="mimir"}
          > (14.4 * 0.050000)
        )
        and on (env,environment,tier,type,stage,component)
        (
          gitlab_component_errors:ratio_5m{component="mimir_ingester",monitor="global",type="mimir"}
          > (14.4 * 0.050000)
        )
      )
      and on(env,environment,tier,type,stage,component)
      (
        sum by(env,environment,tier,type,stage,component) (gitlab_component_ops:rate_1h{component="mimir_ingester",monitor="global",type="mimir"}) >= 1
      )
  - alert: MimirServiceMimirIngesterErrorSLOViolation
    for: 2m
    annotations:
      title: The mimir_ingester SLI of the mimir service (`{{ $labels.stage }}` stage)
        has an error rate violating SLO
      description: |
        The ingester is a stateful component that writes incoming series to long-term storage on the write path and returns series samples for queries on the read path. Incoming time series data from distributors are temporarily stored in the ingester’s memory or offloaded to disk before being written to long-term storage. Eventually, all series are written to disk and periodically uploaded (by default every two hours) to the long-term storage. This SLI monitors the distributor requests. 5xx responses are considered failures.

        Currently the error-rate is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: mimir-main/mimir-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/mimir-main/mimir-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_datasource_id: mimir-metamonitoring
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "3162729023"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(cortex_request_duration_seconds_count{environment="{{ $labels.environment }}",job="mimir/ingester",namespace="mimir",route="/cortex.Ingester/Push",stage="{{ $labels.stage }}",status_code=~"^5.*",type="mimir"}[5m])
        )
      runbook: docs/mimir/README.md
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: error
      slo_alert: "yes"
      team: observability
      user_impacting: "no"
      window: 6h
    expr: |
      (
        (
          gitlab_component_errors:ratio_6h{component="mimir_ingester",monitor="global",type="mimir"}
          > (6 * 0.050000)
        )
        and on (env,environment,tier,type,stage,component)
        (
          gitlab_component_errors:ratio_30m{component="mimir_ingester",monitor="global",type="mimir"}
          > (6 * 0.050000)
        )
      )
      and on(env,environment,tier,type,stage,component)
      (
        sum by(env,environment,tier,type,stage,component) (gitlab_component_ops:rate_6h{component="mimir_ingester",monitor="global",type="mimir"}) >= 0.16667
      )
  - alert: MimirServiceMimirIngesterTrafficCessation
    for: 5m
    annotations:
      title: The mimir_ingester SLI of the mimir service (`{{ $labels.stage }}` stage)
        has not received any traffic in the past 30m
      description: |
        The ingester is a stateful component that writes incoming series to long-term storage on the write path and returns series samples for queries on the read path. Incoming time series data from distributors are temporarily stored in the ingester’s memory or offloaded to disk before being written to long-term storage. Eventually, all series are written to disk and periodically uploaded (by default every two hours) to the long-term storage. This SLI monitors the distributor requests. 5xx responses are considered failures.

        This alert signifies that the SLI is reporting a cessation of traffic; the signal is present, but is zero.
      grafana_dashboard_id: mimir-main/mimir-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/mimir-main/mimir-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_datasource_id: mimir-metamonitoring
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2175678202"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(cortex_request_duration_seconds_count{environment="{{ $labels.environment }}",job="mimir/ingester",namespace="mimir",route="/cortex.Ingester/Push",stage="{{ $labels.stage }}",type="mimir"}[5m])
        )
      runbook: docs/mimir/README.md
    labels:
      aggregation: component
      alert_class: traffic_cessation
      alert_type: cause
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: ops
      slo_alert: "no"
      team: observability
      user_impacting: "no"
    expr: |
      gitlab_component_ops:rate_30m{component="mimir_ingester",monitor="global",stage="main",type="mimir"} == 0
      and
      gitlab_component_ops:rate_30m{component="mimir_ingester",monitor="global",stage="main",type="mimir"} offset 1h >= 0.16666666666666666
  - alert: MimirServiceMimirIngesterTrafficAbsent
    for: 30m
    annotations:
      title: The mimir_ingester SLI of the mimir service (`{{ $labels.stage }}` stage)
        has not reported any traffic in the past 30m
      description: |
        The ingester is a stateful component that writes incoming series to long-term storage on the write path and returns series samples for queries on the read path. Incoming time series data from distributors are temporarily stored in the ingester’s memory or offloaded to disk before being written to long-term storage. Eventually, all series are written to disk and periodically uploaded (by default every two hours) to the long-term storage. This SLI monitors the distributor requests. 5xx responses are considered failures.

        This alert signifies that the SLI was previously reporting traffic, but is no longer - the signal is absent.

        This could be caused by a change to the metrics used in the SLI, or by the service not receiving traffic.
      grafana_dashboard_id: mimir-main/mimir-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/mimir-main/mimir-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_datasource_id: mimir-metamonitoring
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2175678202"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(cortex_request_duration_seconds_count{environment="{{ $labels.environment }}",job="mimir/ingester",namespace="mimir",route="/cortex.Ingester/Push",stage="{{ $labels.stage }}",type="mimir"}[5m])
        )
      runbook: docs/mimir/README.md
    labels:
      aggregation: component
      alert_class: traffic_cessation
      alert_type: cause
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: ops
      slo_alert: "no"
      team: observability
      user_impacting: "no"
    expr: |
      gitlab_component_ops:rate_5m{component="mimir_ingester",monitor="global",stage="main",type="mimir"} offset 1h
      unless
      gitlab_component_ops:rate_5m{component="mimir_ingester",monitor="global",stage="main",type="mimir"}
  - alert: MimirServiceMimirQuerierApdexSLOViolation
    for: 2m
    annotations:
      title: The mimir_querier SLI of the mimir service (`{{ $labels.stage }}` stage)
        has an apdex violating SLO
      description: |
        The querier is a stateless component that evaluates PromQL expressions by fetching time series and labels on the read path. The querier uses the store-gateway component to query the long-term storage and the ingester component to query recently written data. This SLI monitors the querier requests. 5xx responses are considered failures.

        Currently the apdex value is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: mimir-main/mimir-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/mimir-main/mimir-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_datasource_id: mimir-metamonitoring
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1865300405"
      grafana_variables: environment,stage
      promql_template_1: |
        histogram_quantile(
          0.950000,
          sum by (env,environment,tier,stage,le) (
            rate(cortex_querier_request_duration_seconds_bucket{environment="{{ $labels.environment }}",job="mimir/querier",namespace="mimir",route=~"prometheus_(api|prom)_v1_.+",stage="{{ $labels.stage }}",type="mimir"}[5m])
          )
        )
      runbook: docs/mimir/README.md
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: apdex
      slo_alert: "yes"
      user_impacting: "no"
      window: 1h
    expr: |
      (
        (
          gitlab_component_apdex:ratio_1h{component="mimir_querier",monitor="global",type="mimir"}
          < (1 - 14.4 * 0.050000)
        )
        and on (env,environment,tier,type,stage,component)
        (
          gitlab_component_apdex:ratio_5m{component="mimir_querier",monitor="global",type="mimir"}
          < (1 - 14.4 * 0.050000)
        )
      )
      and on(env,environment,tier,type,stage,component)
      (
        sum by(env,environment,tier,type,stage,component) (gitlab_component_ops:rate_1h{component="mimir_querier",monitor="global",type="mimir"}) >= 1
      )
  - alert: MimirServiceMimirQuerierApdexSLOViolation
    for: 2m
    annotations:
      title: The mimir_querier SLI of the mimir service (`{{ $labels.stage }}` stage)
        has an apdex violating SLO
      description: |
        The querier is a stateless component that evaluates PromQL expressions by fetching time series and labels on the read path. The querier uses the store-gateway component to query the long-term storage and the ingester component to query recently written data. This SLI monitors the querier requests. 5xx responses are considered failures.

        Currently the apdex value is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: mimir-main/mimir-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/mimir-main/mimir-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_datasource_id: mimir-metamonitoring
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1865300405"
      grafana_variables: environment,stage
      promql_template_1: |
        histogram_quantile(
          0.950000,
          sum by (env,environment,tier,stage,le) (
            rate(cortex_querier_request_duration_seconds_bucket{environment="{{ $labels.environment }}",job="mimir/querier",namespace="mimir",route=~"prometheus_(api|prom)_v1_.+",stage="{{ $labels.stage }}",type="mimir"}[5m])
          )
        )
      runbook: docs/mimir/README.md
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: apdex
      slo_alert: "yes"
      user_impacting: "no"
      window: 6h
    expr: |
      (
        (
          gitlab_component_apdex:ratio_6h{component="mimir_querier",monitor="global",type="mimir"}
          < (1 - 6 * 0.050000)
        )
        and on (env,environment,tier,type,stage,component)
        (
          gitlab_component_apdex:ratio_30m{component="mimir_querier",monitor="global",type="mimir"}
          < (1 - 6 * 0.050000)
        )
      )
      and on(env,environment,tier,type,stage,component)
      (
        sum by(env,environment,tier,type,stage,component) (gitlab_component_ops:rate_6h{component="mimir_querier",monitor="global",type="mimir"}) >= 0.16667
      )
  - alert: MimirServiceMimirQuerierErrorSLOViolation
    for: 2m
    annotations:
      title: The mimir_querier SLI of the mimir service (`{{ $labels.stage }}` stage)
        has an error rate violating SLO
      description: |
        The querier is a stateless component that evaluates PromQL expressions by fetching time series and labels on the read path. The querier uses the store-gateway component to query the long-term storage and the ingester component to query recently written data. This SLI monitors the querier requests. 5xx responses are considered failures.

        Currently the error-rate is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: mimir-main/mimir-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/mimir-main/mimir-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_datasource_id: mimir-metamonitoring
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2938124288"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(cortex_querier_request_duration_seconds_count{environment="{{ $labels.environment }}",job="mimir/querier",namespace="mimir",route=~"prometheus_(api|prom)_v1_.+",stage="{{ $labels.stage }}",status_code=~"^5.*",type="mimir"}[5m])
        )
      runbook: docs/mimir/README.md
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: error
      slo_alert: "yes"
      user_impacting: "no"
      window: 1h
    expr: |
      (
        (
          gitlab_component_errors:ratio_1h{component="mimir_querier",monitor="global",type="mimir"}
          > (14.4 * 0.050000)
        )
        and on (env,environment,tier,type,stage,component)
        (
          gitlab_component_errors:ratio_5m{component="mimir_querier",monitor="global",type="mimir"}
          > (14.4 * 0.050000)
        )
      )
      and on(env,environment,tier,type,stage,component)
      (
        sum by(env,environment,tier,type,stage,component) (gitlab_component_ops:rate_1h{component="mimir_querier",monitor="global",type="mimir"}) >= 1
      )
  - alert: MimirServiceMimirQuerierErrorSLOViolation
    for: 2m
    annotations:
      title: The mimir_querier SLI of the mimir service (`{{ $labels.stage }}` stage)
        has an error rate violating SLO
      description: |
        The querier is a stateless component that evaluates PromQL expressions by fetching time series and labels on the read path. The querier uses the store-gateway component to query the long-term storage and the ingester component to query recently written data. This SLI monitors the querier requests. 5xx responses are considered failures.

        Currently the error-rate is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: mimir-main/mimir-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/mimir-main/mimir-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_datasource_id: mimir-metamonitoring
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2938124288"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(cortex_querier_request_duration_seconds_count{environment="{{ $labels.environment }}",job="mimir/querier",namespace="mimir",route=~"prometheus_(api|prom)_v1_.+",stage="{{ $labels.stage }}",status_code=~"^5.*",type="mimir"}[5m])
        )
      runbook: docs/mimir/README.md
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: error
      slo_alert: "yes"
      user_impacting: "no"
      window: 6h
    expr: |
      (
        (
          gitlab_component_errors:ratio_6h{component="mimir_querier",monitor="global",type="mimir"}
          > (6 * 0.050000)
        )
        and on (env,environment,tier,type,stage,component)
        (
          gitlab_component_errors:ratio_30m{component="mimir_querier",monitor="global",type="mimir"}
          > (6 * 0.050000)
        )
      )
      and on(env,environment,tier,type,stage,component)
      (
        sum by(env,environment,tier,type,stage,component) (gitlab_component_ops:rate_6h{component="mimir_querier",monitor="global",type="mimir"}) >= 0.16667
      )
  - alert: MimirServiceMimirQuerierTrafficCessation
    for: 5m
    annotations:
      title: The mimir_querier SLI of the mimir service (`{{ $labels.stage }}` stage)
        has not received any traffic in the past 30m
      description: |
        The querier is a stateless component that evaluates PromQL expressions by fetching time series and labels on the read path. The querier uses the store-gateway component to query the long-term storage and the ingester component to query recently written data. This SLI monitors the querier requests. 5xx responses are considered failures.

        This alert signifies that the SLI is reporting a cessation of traffic; the signal is present, but is zero.
      grafana_dashboard_id: mimir-main/mimir-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/mimir-main/mimir-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_datasource_id: mimir-metamonitoring
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1343424081"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(cortex_querier_request_duration_seconds_count{environment="{{ $labels.environment }}",job="mimir/querier",namespace="mimir",route=~"prometheus_(api|prom)_v1_.+",stage="{{ $labels.stage }}",type="mimir"}[5m])
        )
      runbook: docs/mimir/README.md
    labels:
      aggregation: component
      alert_class: traffic_cessation
      alert_type: cause
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: ops
      slo_alert: "no"
      user_impacting: "no"
    expr: |
      gitlab_component_ops:rate_30m{component="mimir_querier",monitor="global",stage="main",type="mimir"} == 0
      and
      gitlab_component_ops:rate_30m{component="mimir_querier",monitor="global",stage="main",type="mimir"} offset 1h >= 0.16666666666666666
  - alert: MimirServiceMimirQuerierTrafficAbsent
    for: 30m
    annotations:
      title: The mimir_querier SLI of the mimir service (`{{ $labels.stage }}` stage)
        has not reported any traffic in the past 30m
      description: |
        The querier is a stateless component that evaluates PromQL expressions by fetching time series and labels on the read path. The querier uses the store-gateway component to query the long-term storage and the ingester component to query recently written data. This SLI monitors the querier requests. 5xx responses are considered failures.

        This alert signifies that the SLI was previously reporting traffic, but is no longer - the signal is absent.

        This could be caused by a change to the metrics used in the SLI, or by the service not receiving traffic.
      grafana_dashboard_id: mimir-main/mimir-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/mimir-main/mimir-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_datasource_id: mimir-metamonitoring
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1343424081"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(cortex_querier_request_duration_seconds_count{environment="{{ $labels.environment }}",job="mimir/querier",namespace="mimir",route=~"prometheus_(api|prom)_v1_.+",stage="{{ $labels.stage }}",type="mimir"}[5m])
        )
      runbook: docs/mimir/README.md
    labels:
      aggregation: component
      alert_class: traffic_cessation
      alert_type: cause
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: ops
      slo_alert: "no"
      user_impacting: "no"
    expr: |
      gitlab_component_ops:rate_5m{component="mimir_querier",monitor="global",stage="main",type="mimir"} offset 1h
      unless
      gitlab_component_ops:rate_5m{component="mimir_querier",monitor="global",stage="main",type="mimir"}
  - alert: MimirServiceMimirQueryFrontendApdexSLOViolation
    for: 2m
    annotations:
      title: The mimir_query_frontend SLI of the mimir service (`{{ $labels.stage
        }}` stage) has an apdex violating SLO
      description: |
        The query-frontend is a stateless component that provides the same API as the querier and can be used to accelerate the read path via caching. This SLI monitors the query-frontend requests. 5xx responses are considered failures.

        Currently the apdex value is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: mimir-main/mimir-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/mimir-main/mimir-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_datasource_id: mimir-metamonitoring
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "4191688554"
      grafana_variables: environment,stage
      promql_template_1: |
        histogram_quantile(
          0.950000,
          sum by (env,environment,tier,stage,le) (
            rate(cortex_request_duration_seconds_bucket{environment="{{ $labels.environment }}",job="mimir/query-frontend",namespace="mimir",route=~"prometheus_(api|prom)_v1_.+",stage="{{ $labels.stage }}",type="mimir"}[5m])
          )
        )
      runbook: docs/mimir/README.md
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: apdex
      slo_alert: "yes"
      team: observability
      user_impacting: "no"
      window: 1h
    expr: |
      (
        (
          gitlab_component_apdex:ratio_1h{component="mimir_query_frontend",monitor="global",type="mimir"}
          < (1 - 14.4 * 0.050000)
        )
        and on (env,environment,tier,type,stage,component)
        (
          gitlab_component_apdex:ratio_5m{component="mimir_query_frontend",monitor="global",type="mimir"}
          < (1 - 14.4 * 0.050000)
        )
      )
      and on(env,environment,tier,type,stage,component)
      (
        sum by(env,environment,tier,type,stage,component) (gitlab_component_ops:rate_1h{component="mimir_query_frontend",monitor="global",type="mimir"}) >= 1
      )
  - alert: MimirServiceMimirQueryFrontendApdexSLOViolation
    for: 2m
    annotations:
      title: The mimir_query_frontend SLI of the mimir service (`{{ $labels.stage
        }}` stage) has an apdex violating SLO
      description: |
        The query-frontend is a stateless component that provides the same API as the querier and can be used to accelerate the read path via caching. This SLI monitors the query-frontend requests. 5xx responses are considered failures.

        Currently the apdex value is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: mimir-main/mimir-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/mimir-main/mimir-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_datasource_id: mimir-metamonitoring
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "4191688554"
      grafana_variables: environment,stage
      promql_template_1: |
        histogram_quantile(
          0.950000,
          sum by (env,environment,tier,stage,le) (
            rate(cortex_request_duration_seconds_bucket{environment="{{ $labels.environment }}",job="mimir/query-frontend",namespace="mimir",route=~"prometheus_(api|prom)_v1_.+",stage="{{ $labels.stage }}",type="mimir"}[5m])
          )
        )
      runbook: docs/mimir/README.md
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: apdex
      slo_alert: "yes"
      team: observability
      user_impacting: "no"
      window: 6h
    expr: |
      (
        (
          gitlab_component_apdex:ratio_6h{component="mimir_query_frontend",monitor="global",type="mimir"}
          < (1 - 6 * 0.050000)
        )
        and on (env,environment,tier,type,stage,component)
        (
          gitlab_component_apdex:ratio_30m{component="mimir_query_frontend",monitor="global",type="mimir"}
          < (1 - 6 * 0.050000)
        )
      )
      and on(env,environment,tier,type,stage,component)
      (
        sum by(env,environment,tier,type,stage,component) (gitlab_component_ops:rate_6h{component="mimir_query_frontend",monitor="global",type="mimir"}) >= 0.16667
      )
  - alert: MimirServiceMimirQueryFrontendErrorSLOViolation
    for: 2m
    annotations:
      title: The mimir_query_frontend SLI of the mimir service (`{{ $labels.stage
        }}` stage) has an error rate violating SLO
      description: |
        The query-frontend is a stateless component that provides the same API as the querier and can be used to accelerate the read path via caching. This SLI monitors the query-frontend requests. 5xx responses are considered failures.

        Currently the error-rate is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: mimir-main/mimir-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/mimir-main/mimir-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_datasource_id: mimir-metamonitoring
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "384966892"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(cortex_request_duration_seconds_count{environment="{{ $labels.environment }}",job="mimir/query-frontend",namespace="mimir",route=~"prometheus_(api|prom)_v1_.+",stage="{{ $labels.stage }}",status_code=~"^5.*",type="mimir"}[5m])
        )
      runbook: docs/mimir/README.md
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: error
      slo_alert: "yes"
      team: observability
      user_impacting: "no"
      window: 1h
    expr: |
      (
        (
          gitlab_component_errors:ratio_1h{component="mimir_query_frontend",monitor="global",type="mimir"}
          > (14.4 * 0.050000)
        )
        and on (env,environment,tier,type,stage,component)
        (
          gitlab_component_errors:ratio_5m{component="mimir_query_frontend",monitor="global",type="mimir"}
          > (14.4 * 0.050000)
        )
      )
      and on(env,environment,tier,type,stage,component)
      (
        sum by(env,environment,tier,type,stage,component) (gitlab_component_ops:rate_1h{component="mimir_query_frontend",monitor="global",type="mimir"}) >= 1
      )
  - alert: MimirServiceMimirQueryFrontendErrorSLOViolation
    for: 2m
    annotations:
      title: The mimir_query_frontend SLI of the mimir service (`{{ $labels.stage
        }}` stage) has an error rate violating SLO
      description: |
        The query-frontend is a stateless component that provides the same API as the querier and can be used to accelerate the read path via caching. This SLI monitors the query-frontend requests. 5xx responses are considered failures.

        Currently the error-rate is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: mimir-main/mimir-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/mimir-main/mimir-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_datasource_id: mimir-metamonitoring
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "384966892"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(cortex_request_duration_seconds_count{environment="{{ $labels.environment }}",job="mimir/query-frontend",namespace="mimir",route=~"prometheus_(api|prom)_v1_.+",stage="{{ $labels.stage }}",status_code=~"^5.*",type="mimir"}[5m])
        )
      runbook: docs/mimir/README.md
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: error
      slo_alert: "yes"
      team: observability
      user_impacting: "no"
      window: 6h
    expr: |
      (
        (
          gitlab_component_errors:ratio_6h{component="mimir_query_frontend",monitor="global",type="mimir"}
          > (6 * 0.050000)
        )
        and on (env,environment,tier,type,stage,component)
        (
          gitlab_component_errors:ratio_30m{component="mimir_query_frontend",monitor="global",type="mimir"}
          > (6 * 0.050000)
        )
      )
      and on(env,environment,tier,type,stage,component)
      (
        sum by(env,environment,tier,type,stage,component) (gitlab_component_ops:rate_6h{component="mimir_query_frontend",monitor="global",type="mimir"}) >= 0.16667
      )
  - alert: MimirServiceMimirQueryFrontendTrafficCessation
    for: 5m
    annotations:
      title: The mimir_query_frontend SLI of the mimir service (`{{ $labels.stage
        }}` stage) has not received any traffic in the past 30m
      description: |
        The query-frontend is a stateless component that provides the same API as the querier and can be used to accelerate the read path via caching. This SLI monitors the query-frontend requests. 5xx responses are considered failures.

        This alert signifies that the SLI is reporting a cessation of traffic; the signal is present, but is zero.
      grafana_dashboard_id: mimir-main/mimir-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/mimir-main/mimir-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_datasource_id: mimir-metamonitoring
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1559358371"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(cortex_request_duration_seconds_count{environment="{{ $labels.environment }}",job="mimir/query-frontend",namespace="mimir",route=~"prometheus_(api|prom)_v1_.+",stage="{{ $labels.stage }}",type="mimir"}[5m])
        )
      runbook: docs/mimir/README.md
    labels:
      aggregation: component
      alert_class: traffic_cessation
      alert_type: cause
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: ops
      slo_alert: "no"
      team: observability
      user_impacting: "no"
    expr: |
      gitlab_component_ops:rate_30m{component="mimir_query_frontend",monitor="global",stage="main",type="mimir"} == 0
      and
      gitlab_component_ops:rate_30m{component="mimir_query_frontend",monitor="global",stage="main",type="mimir"} offset 1h >= 0.16666666666666666
  - alert: MimirServiceMimirQueryFrontendTrafficAbsent
    for: 30m
    annotations:
      title: The mimir_query_frontend SLI of the mimir service (`{{ $labels.stage
        }}` stage) has not reported any traffic in the past 30m
      description: |
        The query-frontend is a stateless component that provides the same API as the querier and can be used to accelerate the read path via caching. This SLI monitors the query-frontend requests. 5xx responses are considered failures.

        This alert signifies that the SLI was previously reporting traffic, but is no longer - the signal is absent.

        This could be caused by a change to the metrics used in the SLI, or by the service not receiving traffic.
      grafana_dashboard_id: mimir-main/mimir-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/mimir-main/mimir-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_datasource_id: mimir-metamonitoring
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1559358371"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(cortex_request_duration_seconds_count{environment="{{ $labels.environment }}",job="mimir/query-frontend",namespace="mimir",route=~"prometheus_(api|prom)_v1_.+",stage="{{ $labels.stage }}",type="mimir"}[5m])
        )
      runbook: docs/mimir/README.md
    labels:
      aggregation: component
      alert_class: traffic_cessation
      alert_type: cause
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: ops
      slo_alert: "no"
      team: observability
      user_impacting: "no"
    expr: |
      gitlab_component_ops:rate_5m{component="mimir_query_frontend",monitor="global",stage="main",type="mimir"} offset 1h
      unless
      gitlab_component_ops:rate_5m{component="mimir_query_frontend",monitor="global",stage="main",type="mimir"}
  - alert: MimirServiceMimirQuerySchedulerApdexSLOViolation
    for: 2m
    annotations:
      title: The mimir_query_scheduler SLI of the mimir service (`{{ $labels.stage
        }}` stage) has an apdex violating SLO
      description: |
        The query-scheduler is an optional, stateless component that retains a queue of queries to execute, and distributes the workload to available queriers. This enabled easier scaling of the query-frontends This SLI monitors the query-scheduler requests. 5xx responses are considered failures.

        Currently the apdex value is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: mimir-main/mimir-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/mimir-main/mimir-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_datasource_id: mimir-metamonitoring
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1540378125"
      grafana_variables: environment,stage
      promql_template_1: |
        histogram_quantile(
          0.950000,
          sum by (env,environment,tier,stage,le) (
            rate(cortex_query_scheduler_queue_duration_seconds_bucket{environment="{{ $labels.environment }}",job="mimir/query-scheduler",namespace="mimir",stage="{{ $labels.stage }}",type="mimir"}[5m])
          )
        )
      runbook: docs/mimir/README.md
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: apdex
      slo_alert: "yes"
      team: observability
      user_impacting: "no"
      window: 1h
    expr: |
      (
        (
          gitlab_component_apdex:ratio_1h{component="mimir_query_scheduler",monitor="global",type="mimir"}
          < (1 - 14.4 * 0.050000)
        )
        and on (env,environment,tier,type,stage,component)
        (
          gitlab_component_apdex:ratio_5m{component="mimir_query_scheduler",monitor="global",type="mimir"}
          < (1 - 14.4 * 0.050000)
        )
      )
      and on(env,environment,tier,type,stage,component)
      (
        sum by(env,environment,tier,type,stage,component) (gitlab_component_ops:rate_1h{component="mimir_query_scheduler",monitor="global",type="mimir"}) >= 1
      )
  - alert: MimirServiceMimirQuerySchedulerApdexSLOViolation
    for: 2m
    annotations:
      title: The mimir_query_scheduler SLI of the mimir service (`{{ $labels.stage
        }}` stage) has an apdex violating SLO
      description: |
        The query-scheduler is an optional, stateless component that retains a queue of queries to execute, and distributes the workload to available queriers. This enabled easier scaling of the query-frontends This SLI monitors the query-scheduler requests. 5xx responses are considered failures.

        Currently the apdex value is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: mimir-main/mimir-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/mimir-main/mimir-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_datasource_id: mimir-metamonitoring
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1540378125"
      grafana_variables: environment,stage
      promql_template_1: |
        histogram_quantile(
          0.950000,
          sum by (env,environment,tier,stage,le) (
            rate(cortex_query_scheduler_queue_duration_seconds_bucket{environment="{{ $labels.environment }}",job="mimir/query-scheduler",namespace="mimir",stage="{{ $labels.stage }}",type="mimir"}[5m])
          )
        )
      runbook: docs/mimir/README.md
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: apdex
      slo_alert: "yes"
      team: observability
      user_impacting: "no"
      window: 6h
    expr: |
      (
        (
          gitlab_component_apdex:ratio_6h{component="mimir_query_scheduler",monitor="global",type="mimir"}
          < (1 - 6 * 0.050000)
        )
        and on (env,environment,tier,type,stage,component)
        (
          gitlab_component_apdex:ratio_30m{component="mimir_query_scheduler",monitor="global",type="mimir"}
          < (1 - 6 * 0.050000)
        )
      )
      and on(env,environment,tier,type,stage,component)
      (
        sum by(env,environment,tier,type,stage,component) (gitlab_component_ops:rate_6h{component="mimir_query_scheduler",monitor="global",type="mimir"}) >= 0.16667
      )
  - alert: MimirServiceMimirQuerySchedulerErrorSLOViolation
    for: 2m
    annotations:
      title: The mimir_query_scheduler SLI of the mimir service (`{{ $labels.stage
        }}` stage) has an error rate violating SLO
      description: |
        The query-scheduler is an optional, stateless component that retains a queue of queries to execute, and distributes the workload to available queriers. This enabled easier scaling of the query-frontends This SLI monitors the query-scheduler requests. 5xx responses are considered failures.

        Currently the error-rate is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: mimir-main/mimir-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/mimir-main/mimir-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_datasource_id: mimir-metamonitoring
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "694965604"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(cortex_query_scheduler_queue_duration_seconds_count{environment="{{ $labels.environment }}",job="mimir/query-scheduler",namespace="mimir",stage="{{ $labels.stage }}",status_code=~"^5.*",type="mimir"}[5m])
        )
      runbook: docs/mimir/README.md
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: error
      slo_alert: "yes"
      team: observability
      user_impacting: "no"
      window: 1h
    expr: |
      (
        (
          gitlab_component_errors:ratio_1h{component="mimir_query_scheduler",monitor="global",type="mimir"}
          > (14.4 * 0.050000)
        )
        and on (env,environment,tier,type,stage,component)
        (
          gitlab_component_errors:ratio_5m{component="mimir_query_scheduler",monitor="global",type="mimir"}
          > (14.4 * 0.050000)
        )
      )
      and on(env,environment,tier,type,stage,component)
      (
        sum by(env,environment,tier,type,stage,component) (gitlab_component_ops:rate_1h{component="mimir_query_scheduler",monitor="global",type="mimir"}) >= 1
      )
  - alert: MimirServiceMimirQuerySchedulerErrorSLOViolation
    for: 2m
    annotations:
      title: The mimir_query_scheduler SLI of the mimir service (`{{ $labels.stage
        }}` stage) has an error rate violating SLO
      description: |
        The query-scheduler is an optional, stateless component that retains a queue of queries to execute, and distributes the workload to available queriers. This enabled easier scaling of the query-frontends This SLI monitors the query-scheduler requests. 5xx responses are considered failures.

        Currently the error-rate is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: mimir-main/mimir-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/mimir-main/mimir-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_datasource_id: mimir-metamonitoring
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "694965604"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(cortex_query_scheduler_queue_duration_seconds_count{environment="{{ $labels.environment }}",job="mimir/query-scheduler",namespace="mimir",stage="{{ $labels.stage }}",status_code=~"^5.*",type="mimir"}[5m])
        )
      runbook: docs/mimir/README.md
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: error
      slo_alert: "yes"
      team: observability
      user_impacting: "no"
      window: 6h
    expr: |
      (
        (
          gitlab_component_errors:ratio_6h{component="mimir_query_scheduler",monitor="global",type="mimir"}
          > (6 * 0.050000)
        )
        and on (env,environment,tier,type,stage,component)
        (
          gitlab_component_errors:ratio_30m{component="mimir_query_scheduler",monitor="global",type="mimir"}
          > (6 * 0.050000)
        )
      )
      and on(env,environment,tier,type,stage,component)
      (
        sum by(env,environment,tier,type,stage,component) (gitlab_component_ops:rate_6h{component="mimir_query_scheduler",monitor="global",type="mimir"}) >= 0.16667
      )
  - alert: MimirServiceMimirQuerySchedulerTrafficCessation
    for: 5m
    annotations:
      title: The mimir_query_scheduler SLI of the mimir service (`{{ $labels.stage
        }}` stage) has not received any traffic in the past 30m
      description: |
        The query-scheduler is an optional, stateless component that retains a queue of queries to execute, and distributes the workload to available queriers. This enabled easier scaling of the query-frontends This SLI monitors the query-scheduler requests. 5xx responses are considered failures.

        This alert signifies that the SLI is reporting a cessation of traffic; the signal is present, but is zero.
      grafana_dashboard_id: mimir-main/mimir-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/mimir-main/mimir-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_datasource_id: mimir-metamonitoring
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "3774704962"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(cortex_query_scheduler_queue_duration_seconds_count{environment="{{ $labels.environment }}",job="mimir/query-scheduler",namespace="mimir",stage="{{ $labels.stage }}",type="mimir"}[5m])
        )
      runbook: docs/mimir/README.md
    labels:
      aggregation: component
      alert_class: traffic_cessation
      alert_type: cause
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: ops
      slo_alert: "no"
      team: observability
      user_impacting: "no"
    expr: |
      gitlab_component_ops:rate_30m{component="mimir_query_scheduler",monitor="global",stage="main",type="mimir"} == 0
      and
      gitlab_component_ops:rate_30m{component="mimir_query_scheduler",monitor="global",stage="main",type="mimir"} offset 1h >= 0.16666666666666666
  - alert: MimirServiceMimirQuerySchedulerTrafficAbsent
    for: 30m
    annotations:
      title: The mimir_query_scheduler SLI of the mimir service (`{{ $labels.stage
        }}` stage) has not reported any traffic in the past 30m
      description: |
        The query-scheduler is an optional, stateless component that retains a queue of queries to execute, and distributes the workload to available queriers. This enabled easier scaling of the query-frontends This SLI monitors the query-scheduler requests. 5xx responses are considered failures.

        This alert signifies that the SLI was previously reporting traffic, but is no longer - the signal is absent.

        This could be caused by a change to the metrics used in the SLI, or by the service not receiving traffic.
      grafana_dashboard_id: mimir-main/mimir-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/mimir-main/mimir-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_datasource_id: mimir-metamonitoring
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "3774704962"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(cortex_query_scheduler_queue_duration_seconds_count{environment="{{ $labels.environment }}",job="mimir/query-scheduler",namespace="mimir",stage="{{ $labels.stage }}",type="mimir"}[5m])
        )
      runbook: docs/mimir/README.md
    labels:
      aggregation: component
      alert_class: traffic_cessation
      alert_type: cause
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: ops
      slo_alert: "no"
      team: observability
      user_impacting: "no"
    expr: |
      gitlab_component_ops:rate_5m{component="mimir_query_scheduler",monitor="global",stage="main",type="mimir"} offset 1h
      unless
      gitlab_component_ops:rate_5m{component="mimir_query_scheduler",monitor="global",stage="main",type="mimir"}
  - alert: MimirServiceMimirRulerErrorSLOViolation
    for: 2m
    annotations:
      title: The mimir_ruler SLI of the mimir service (`{{ $labels.stage }}` stage)
        has an error rate violating SLO
      description: |
        The ruler component evaluates PromQL expressions defined in recording and alerting rules. Each tenant has a set of recording and alerting rules and can group those rules into namespaces. This SLI monitors the rulers evaluation failures.

        Currently the error-rate is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: mimir-main/mimir-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/mimir-main/mimir-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_datasource_id: mimir-metamonitoring
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1867876924"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(cortex_prometheus_rule_evaluation_failures_total{environment="{{ $labels.environment }}",job="mimir/ruler",namespace="mimir",stage="{{ $labels.stage }}",type="mimir"}[5m])
        )
      runbook: docs/mimir/README.md
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: error
      slo_alert: "yes"
      team: observability
      user_impacting: "no"
      window: 1h
    expr: |
      (
        (
          gitlab_component_errors:ratio_1h{component="mimir_ruler",monitor="global",type="mimir"}
          > (14.4 * 0.050000)
        )
        and on (env,environment,tier,type,stage,component)
        (
          gitlab_component_errors:ratio_5m{component="mimir_ruler",monitor="global",type="mimir"}
          > (14.4 * 0.050000)
        )
      )
      and on(env,environment,tier,type,stage,component)
      (
        sum by(env,environment,tier,type,stage,component) (gitlab_component_ops:rate_1h{component="mimir_ruler",monitor="global",type="mimir"}) >= 1
      )
  - alert: MimirServiceMimirRulerErrorSLOViolation
    for: 2m
    annotations:
      title: The mimir_ruler SLI of the mimir service (`{{ $labels.stage }}` stage)
        has an error rate violating SLO
      description: |
        The ruler component evaluates PromQL expressions defined in recording and alerting rules. Each tenant has a set of recording and alerting rules and can group those rules into namespaces. This SLI monitors the rulers evaluation failures.

        Currently the error-rate is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: mimir-main/mimir-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/mimir-main/mimir-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_datasource_id: mimir-metamonitoring
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1867876924"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(cortex_prometheus_rule_evaluation_failures_total{environment="{{ $labels.environment }}",job="mimir/ruler",namespace="mimir",stage="{{ $labels.stage }}",type="mimir"}[5m])
        )
      runbook: docs/mimir/README.md
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: error
      slo_alert: "yes"
      team: observability
      user_impacting: "no"
      window: 6h
    expr: |
      (
        (
          gitlab_component_errors:ratio_6h{component="mimir_ruler",monitor="global",type="mimir"}
          > (6 * 0.050000)
        )
        and on (env,environment,tier,type,stage,component)
        (
          gitlab_component_errors:ratio_30m{component="mimir_ruler",monitor="global",type="mimir"}
          > (6 * 0.050000)
        )
      )
      and on(env,environment,tier,type,stage,component)
      (
        sum by(env,environment,tier,type,stage,component) (gitlab_component_ops:rate_6h{component="mimir_ruler",monitor="global",type="mimir"}) >= 0.16667
      )
  - alert: MimirServiceMimirRulerTrafficCessation
    for: 5m
    annotations:
      title: The mimir_ruler SLI of the mimir service (`{{ $labels.stage }}` stage)
        has not received any traffic in the past 30m
      description: |
        The ruler component evaluates PromQL expressions defined in recording and alerting rules. Each tenant has a set of recording and alerting rules and can group those rules into namespaces. This SLI monitors the rulers evaluation failures.

        This alert signifies that the SLI is reporting a cessation of traffic; the signal is present, but is zero.
      grafana_dashboard_id: mimir-main/mimir-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/mimir-main/mimir-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_datasource_id: mimir-metamonitoring
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2443479007"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(cortex_prometheus_rule_evaluations_total{environment="{{ $labels.environment }}",job="mimir/ruler",namespace="mimir",stage="{{ $labels.stage }}",type="mimir"}[5m])
        )
      runbook: docs/mimir/README.md
    labels:
      aggregation: component
      alert_class: traffic_cessation
      alert_type: cause
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: ops
      slo_alert: "no"
      team: observability
      user_impacting: "no"
    expr: |
      gitlab_component_ops:rate_30m{component="mimir_ruler",monitor="global",stage="main",type="mimir"} == 0
      and
      gitlab_component_ops:rate_30m{component="mimir_ruler",monitor="global",stage="main",type="mimir"} offset 1h >= 0.16666666666666666
  - alert: MimirServiceMimirRulerTrafficAbsent
    for: 30m
    annotations:
      title: The mimir_ruler SLI of the mimir service (`{{ $labels.stage }}` stage)
        has not reported any traffic in the past 30m
      description: |
        The ruler component evaluates PromQL expressions defined in recording and alerting rules. Each tenant has a set of recording and alerting rules and can group those rules into namespaces. This SLI monitors the rulers evaluation failures.

        This alert signifies that the SLI was previously reporting traffic, but is no longer - the signal is absent.

        This could be caused by a change to the metrics used in the SLI, or by the service not receiving traffic.
      grafana_dashboard_id: mimir-main/mimir-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/mimir-main/mimir-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_datasource_id: mimir-metamonitoring
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2443479007"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(cortex_prometheus_rule_evaluations_total{environment="{{ $labels.environment }}",job="mimir/ruler",namespace="mimir",stage="{{ $labels.stage }}",type="mimir"}[5m])
        )
      runbook: docs/mimir/README.md
    labels:
      aggregation: component
      alert_class: traffic_cessation
      alert_type: cause
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: ops
      slo_alert: "no"
      team: observability
      user_impacting: "no"
    expr: |
      gitlab_component_ops:rate_5m{component="mimir_ruler",monitor="global",stage="main",type="mimir"} offset 1h
      unless
      gitlab_component_ops:rate_5m{component="mimir_ruler",monitor="global",stage="main",type="mimir"}
  - alert: MimirServiceMimirStoreGatewayApdexSLOViolation
    for: 2m
    annotations:
      title: The mimir_store_gateway SLI of the mimir service (`{{ $labels.stage }}`
        stage) has an apdex violating SLO
      description: |
        The store-gateway component, which is stateful, queries blocks from long-term storage. On the read path, the querier and the ruler use the store-gateway when handling the query, whether the query comes from a user or from when a rule is being evaluated. This SLI monitors the store-gatewau requests. 5xx responses are considered failures.

        Currently the apdex value is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: mimir-main/mimir-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/mimir-main/mimir-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_datasource_id: mimir-metamonitoring
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "464885285"
      grafana_variables: environment,stage
      promql_template_1: |
        histogram_quantile(
          0.950000,
          sum by (env,environment,tier,stage,le) (
            rate(cortex_request_duration_seconds_bucket{environment="{{ $labels.environment }}",job="mimir/store-gateway",namespace="mimir",route=~"/gatewaypb\\.StoreGateway/.*",stage="{{ $labels.stage }}",type="mimir"}[5m])
          )
        )
      runbook: docs/mimir/README.md
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: apdex
      slo_alert: "yes"
      team: observability
      user_impacting: "no"
      window: 1h
    expr: |
      (
        (
          gitlab_component_apdex:ratio_1h{component="mimir_store_gateway",monitor="global",type="mimir"}
          < (1 - 14.4 * 0.050000)
        )
        and on (env,environment,tier,type,stage,component)
        (
          gitlab_component_apdex:ratio_5m{component="mimir_store_gateway",monitor="global",type="mimir"}
          < (1 - 14.4 * 0.050000)
        )
      )
      and on(env,environment,tier,type,stage,component)
      (
        sum by(env,environment,tier,type,stage,component) (gitlab_component_ops:rate_1h{component="mimir_store_gateway",monitor="global",type="mimir"}) >= 1
      )
  - alert: MimirServiceMimirStoreGatewayApdexSLOViolation
    for: 2m
    annotations:
      title: The mimir_store_gateway SLI of the mimir service (`{{ $labels.stage }}`
        stage) has an apdex violating SLO
      description: |
        The store-gateway component, which is stateful, queries blocks from long-term storage. On the read path, the querier and the ruler use the store-gateway when handling the query, whether the query comes from a user or from when a rule is being evaluated. This SLI monitors the store-gatewau requests. 5xx responses are considered failures.

        Currently the apdex value is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: mimir-main/mimir-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/mimir-main/mimir-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_datasource_id: mimir-metamonitoring
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "464885285"
      grafana_variables: environment,stage
      promql_template_1: |
        histogram_quantile(
          0.950000,
          sum by (env,environment,tier,stage,le) (
            rate(cortex_request_duration_seconds_bucket{environment="{{ $labels.environment }}",job="mimir/store-gateway",namespace="mimir",route=~"/gatewaypb\\.StoreGateway/.*",stage="{{ $labels.stage }}",type="mimir"}[5m])
          )
        )
      runbook: docs/mimir/README.md
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: apdex
      slo_alert: "yes"
      team: observability
      user_impacting: "no"
      window: 6h
    expr: |
      (
        (
          gitlab_component_apdex:ratio_6h{component="mimir_store_gateway",monitor="global",type="mimir"}
          < (1 - 6 * 0.050000)
        )
        and on (env,environment,tier,type,stage,component)
        (
          gitlab_component_apdex:ratio_30m{component="mimir_store_gateway",monitor="global",type="mimir"}
          < (1 - 6 * 0.050000)
        )
      )
      and on(env,environment,tier,type,stage,component)
      (
        sum by(env,environment,tier,type,stage,component) (gitlab_component_ops:rate_6h{component="mimir_store_gateway",monitor="global",type="mimir"}) >= 0.16667
      )
  - alert: MimirServiceMimirStoreGatewayErrorSLOViolation
    for: 2m
    annotations:
      title: The mimir_store_gateway SLI of the mimir service (`{{ $labels.stage }}`
        stage) has an error rate violating SLO
      description: |
        The store-gateway component, which is stateful, queries blocks from long-term storage. On the read path, the querier and the ruler use the store-gateway when handling the query, whether the query comes from a user or from when a rule is being evaluated. This SLI monitors the store-gatewau requests. 5xx responses are considered failures.

        Currently the error-rate is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: mimir-main/mimir-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/mimir-main/mimir-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_datasource_id: mimir-metamonitoring
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "3226782895"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(cortex_request_duration_seconds_count{environment="{{ $labels.environment }}",job="mimir/store-gateway",namespace="mimir",route=~"/gatewaypb\\.StoreGateway/.*",stage="{{ $labels.stage }}",status_code=~"^5.*",type="mimir"}[5m])
        )
      runbook: docs/mimir/README.md
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: error
      slo_alert: "yes"
      team: observability
      user_impacting: "no"
      window: 1h
    expr: |
      (
        (
          gitlab_component_errors:ratio_1h{component="mimir_store_gateway",monitor="global",type="mimir"}
          > (14.4 * 0.050000)
        )
        and on (env,environment,tier,type,stage,component)
        (
          gitlab_component_errors:ratio_5m{component="mimir_store_gateway",monitor="global",type="mimir"}
          > (14.4 * 0.050000)
        )
      )
      and on(env,environment,tier,type,stage,component)
      (
        sum by(env,environment,tier,type,stage,component) (gitlab_component_ops:rate_1h{component="mimir_store_gateway",monitor="global",type="mimir"}) >= 1
      )
  - alert: MimirServiceMimirStoreGatewayErrorSLOViolation
    for: 2m
    annotations:
      title: The mimir_store_gateway SLI of the mimir service (`{{ $labels.stage }}`
        stage) has an error rate violating SLO
      description: |
        The store-gateway component, which is stateful, queries blocks from long-term storage. On the read path, the querier and the ruler use the store-gateway when handling the query, whether the query comes from a user or from when a rule is being evaluated. This SLI monitors the store-gatewau requests. 5xx responses are considered failures.

        Currently the error-rate is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: mimir-main/mimir-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/mimir-main/mimir-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_datasource_id: mimir-metamonitoring
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "3226782895"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(cortex_request_duration_seconds_count{environment="{{ $labels.environment }}",job="mimir/store-gateway",namespace="mimir",route=~"/gatewaypb\\.StoreGateway/.*",stage="{{ $labels.stage }}",status_code=~"^5.*",type="mimir"}[5m])
        )
      runbook: docs/mimir/README.md
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: error
      slo_alert: "yes"
      team: observability
      user_impacting: "no"
      window: 6h
    expr: |
      (
        (
          gitlab_component_errors:ratio_6h{component="mimir_store_gateway",monitor="global",type="mimir"}
          > (6 * 0.050000)
        )
        and on (env,environment,tier,type,stage,component)
        (
          gitlab_component_errors:ratio_30m{component="mimir_store_gateway",monitor="global",type="mimir"}
          > (6 * 0.050000)
        )
      )
      and on(env,environment,tier,type,stage,component)
      (
        sum by(env,environment,tier,type,stage,component) (gitlab_component_ops:rate_6h{component="mimir_store_gateway",monitor="global",type="mimir"}) >= 0.16667
      )
  - alert: MimirServiceMimirStoreGatewayTrafficCessation
    for: 5m
    annotations:
      title: The mimir_store_gateway SLI of the mimir service (`{{ $labels.stage }}`
        stage) has not received any traffic in the past 30m
      description: |
        The store-gateway component, which is stateful, queries blocks from long-term storage. On the read path, the querier and the ruler use the store-gateway when handling the query, whether the query comes from a user or from when a rule is being evaluated. This SLI monitors the store-gatewau requests. 5xx responses are considered failures.

        This alert signifies that the SLI is reporting a cessation of traffic; the signal is present, but is zero.
      grafana_dashboard_id: mimir-main/mimir-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/mimir-main/mimir-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_datasource_id: mimir-metamonitoring
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "3298569033"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(cortex_request_duration_seconds_count{environment="{{ $labels.environment }}",job="mimir/store-gateway",namespace="mimir",route=~"/gatewaypb\\.StoreGateway/.*",stage="{{ $labels.stage }}",type="mimir"}[5m])
        )
      runbook: docs/mimir/README.md
    labels:
      aggregation: component
      alert_class: traffic_cessation
      alert_type: cause
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: ops
      slo_alert: "no"
      team: observability
      user_impacting: "no"
    expr: |
      gitlab_component_ops:rate_30m{component="mimir_store_gateway",monitor="global",stage="main",type="mimir"} == 0
      and
      gitlab_component_ops:rate_30m{component="mimir_store_gateway",monitor="global",stage="main",type="mimir"} offset 1h >= 0.16666666666666666
  - alert: MimirServiceMimirStoreGatewayTrafficAbsent
    for: 30m
    annotations:
      title: The mimir_store_gateway SLI of the mimir service (`{{ $labels.stage }}`
        stage) has not reported any traffic in the past 30m
      description: |
        The store-gateway component, which is stateful, queries blocks from long-term storage. On the read path, the querier and the ruler use the store-gateway when handling the query, whether the query comes from a user or from when a rule is being evaluated. This SLI monitors the store-gatewau requests. 5xx responses are considered failures.

        This alert signifies that the SLI was previously reporting traffic, but is no longer - the signal is absent.

        This could be caused by a change to the metrics used in the SLI, or by the service not receiving traffic.
      grafana_dashboard_id: mimir-main/mimir-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/mimir-main/mimir-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_datasource_id: mimir-metamonitoring
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "3298569033"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(cortex_request_duration_seconds_count{environment="{{ $labels.environment }}",job="mimir/store-gateway",namespace="mimir",route=~"/gatewaypb\\.StoreGateway/.*",stage="{{ $labels.stage }}",type="mimir"}[5m])
        )
      runbook: docs/mimir/README.md
    labels:
      aggregation: component
      alert_class: traffic_cessation
      alert_type: cause
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: ops
      slo_alert: "no"
      team: observability
      user_impacting: "no"
    expr: |
      gitlab_component_ops:rate_5m{component="mimir_store_gateway",monitor="global",stage="main",type="mimir"} offset 1h
      unless
      gitlab_component_ops:rate_5m{component="mimir_store_gateway",monitor="global",stage="main",type="mimir"}
