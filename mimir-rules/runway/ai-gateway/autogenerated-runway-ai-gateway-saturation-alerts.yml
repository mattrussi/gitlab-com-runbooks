# WARNING. DO NOT EDIT THIS FILE BY HAND. USE ./mimir-rules-jsonnet/saturation.jsonnet TO GENERATE IT
# YOUR CHANGES WILL BE OVERRIDDEN
groups:
- name: GitLab Component Saturation Statistics
  interval: 5m
  rules:
  - record: gitlab_component_saturation:ratio_quantile95_1w
    expr: quantile_over_time(0.95, gitlab_component_saturation:ratio{type="ai-gateway"}[1w])
  - record: gitlab_component_saturation:ratio_quantile99_1w
    expr: quantile_over_time(0.99, gitlab_component_saturation:ratio{type="ai-gateway"}[1w])
  - record: gitlab_component_saturation:ratio_quantile95_1h
    expr: quantile_over_time(0.95, gitlab_component_saturation:ratio{type="ai-gateway"}[1h])
  - record: gitlab_component_saturation:ratio_quantile99_1h
    expr: quantile_over_time(0.99, gitlab_component_saturation:ratio{type="ai-gateway"}[1h])
  - record: gitlab_component_saturation:ratio_avg_1h
    expr: avg_over_time(gitlab_component_saturation:ratio{type="ai-gateway"}[1h])
- name: GitLab Saturation Alerts
  interval: 1m
  rules:
  - alert: component_saturation_slo_out_of_bounds:gcp_quota_limit_vertex_ai
    for: 15m
    annotations:
      title: The GCP Quota utilization per environment resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage) has a saturation exceeding SLO and
        is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the GCP Quota utilization per environment resource:

        GCP Quota utilization / limit ratio for all vertex AI models except code-gecko.

        Saturation on the quota may cause problems with the requests.

        To fix, we can request a quota increase for the specific resource to the GCP support team.
      grafana_dashboard_id: alerts-sat_gcp_quota_limit_vertex_ai
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_gcp_quota_limit_vertex_ai?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_datasource_id: mimir-runway
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1515902021"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(base_model,environment,location,region,shard,stage,tier,type) (
          clamp_min(
            clamp_max(
              (
                sum without (method) (stackdriver_aiplatform_googleapis_com_location_aiplatform_googleapis_com_quota_online_prediction_requests_per_base_model_usage{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}",base_model!="code-gecko"})
              /
                stackdriver_aiplatform_googleapis_com_location_aiplatform_googleapis_com_quota_online_prediction_requests_per_base_model_limit{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}",base_model!="code-gecko"}
              ) > 0
              ,
              1)
          ,
          0)
        )
      promql_template_1: |
        max by(base_model,environment,location,region,shard,stage,tier,type) (
          clamp_min(
            clamp_max(
              (
                sum without (method) (stackdriver_aiplatform_googleapis_com_location_aiplatform_googleapis_com_quota_online_prediction_requests_per_base_model_usage{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}",base_model!="code-gecko"})
              /
                stackdriver_aiplatform_googleapis_com_location_aiplatform_googleapis_com_quota_online_prediction_requests_per_base_model_limit{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}",base_model!="code-gecko"}
              ) > 0
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
    expr: |
      gitlab_component_saturation:ratio{component="gcp_quota_limit_vertex_ai",type="ai-gateway"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="gcp_quota_limit_vertex_ai"}
  - alert: component_saturation_slo_out_of_bounds:gcp_quota_limit_vertex_ai_code_gecko
    for: 15m
    annotations:
      title: The GCP Quota utilization per environment resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage) has a saturation exceeding SLO and
        is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the GCP Quota utilization per environment resource:

        GCP Quota utilization / limit ratio for Vertex AI for code-gecko model (used by code completion part of Code Suggestions)

        Saturation on the quota may cause problems with code completion requests.

        To fix, we can request a quota increase for the specific resource to the GCP support team.
      grafana_dashboard_id: alerts-sat_vertex_ai_code_gecko_quota
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_vertex_ai_code_gecko_quota?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_datasource_id: mimir-runway
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "3658506870"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(base_model,environment,location,region,shard,stage,tier,type) (
          clamp_min(
            clamp_max(
              (
                sum without (method) (stackdriver_aiplatform_googleapis_com_location_aiplatform_googleapis_com_quota_online_prediction_requests_per_base_model_usage{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}",base_model="code-gecko"})
              /
                stackdriver_aiplatform_googleapis_com_location_aiplatform_googleapis_com_quota_online_prediction_requests_per_base_model_limit{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}",base_model="code-gecko"}
              ) > 0
              ,
              1)
          ,
          0)
        )
      promql_template_1: |
        max by(base_model,environment,location,region,shard,stage,tier,type) (
          clamp_min(
            clamp_max(
              (
                sum without (method) (stackdriver_aiplatform_googleapis_com_location_aiplatform_googleapis_com_quota_online_prediction_requests_per_base_model_usage{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}",base_model="code-gecko"})
              /
                stackdriver_aiplatform_googleapis_com_location_aiplatform_googleapis_com_quota_online_prediction_requests_per_base_model_limit{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}",base_model="code-gecko"}
              ) > 0
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
    expr: |
      gitlab_component_saturation:ratio{component="gcp_quota_limit_vertex_ai_code_gecko",type="ai-gateway"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="gcp_quota_limit_vertex_ai_code_gecko"}
  - alert: component_saturation_slo_out_of_bounds:max_concurrent_inferences
    for: 5m
    annotations:
      title: The Maximum number of concurrent inferences to a large language model
        resource of the {{ $labels.type }} service ({{ $labels.stage }} stage) has
        a saturation exceeding SLO and is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Maximum number of concurrent inferences to a large language model resource:

        The maximum number of inferences (requests) we can concurrently make to a single LLM.

        Anthropic is enforcing different concurrency limits per model they provide. When we make a new request when we already have the maximum number of concurrent requests in flight, Anthropic responds with a 429. The client-library in the AI-gateway is set to retry once on errors.

        When Anthropic rejects the requests, this leads to a 500 error in the AI-gateway and Workhorse. This results in clients not getting a response (code suggestion).

        To fix this, we need to request a larger concurrency to Anthropic. Currently in the `#ext-anthropic` slack channel.

        Bear in mind that this metric is sampled at scrape time. So it is only an approximation of the actual number of requests in flight. We should assume the actual utilization is higher and request increases sooner.
      grafana_dashboard_id: alerts-max_concurrent_inferences
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-max_concurrent_inferences?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_datasource_id: mimir-runway
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "621984338"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment,model_engine,model_name,shard,stage,tier,type) (
          clamp_min(
            clamp_max(
              sum by (environment,model_engine,model_name,shard,stage,tier,type)(max_over_time(model_inferences_in_flight{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[10m]))
              /
              min by (environment,model_engine,model_name,shard,stage,tier,type)(min_over_time(model_inferences_max_concurrent{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[10m]))
              ,
              1)
          ,
          0)
        )
      promql_template_1: |
        max by(environment,model_engine,model_name,shard,stage,tier,type) (
          clamp_min(
            clamp_max(
              sum by (environment,model_engine,model_name,shard,stage,tier,type)(max_over_time(model_inferences_in_flight{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[10m]))
              /
              min by (environment,model_engine,model_name,shard,stage,tier,type)(min_over_time(model_inferences_max_concurrent{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[10m]))
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s3
    expr: |
      gitlab_component_saturation:ratio{component="max_concurrent_inferences",type="ai-gateway"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="max_concurrent_inferences"}
  - alert: component_saturation_slo_out_of_bounds:max_concurrent_inferences_per_engine
    for: 5m
    annotations:
      title: The Maximum number of concurrent inferences to a large language model
        resource of the {{ $labels.type }} service ({{ $labels.stage }} stage) has
        a saturation exceeding SLO and is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Maximum number of concurrent inferences to a large language model resource:

        The maximum number of inferences (requests) we can concurrently make to a all models for a single provider (engine).

        Anthropic is enforcing different concurrency limits per model they provide. But across all models, we can not exceed the global limit that is equal to the largest allowed limit.

        When Anthropic rejects the requests, this leads to a 500 error in the AI-gateway and Workhorse. This results in clients not getting a response (code suggestion).

        To fix this, we need to request a larger concurrency to Anthropic. Currently in the `#ext-anthropic` slack channel.

        Bear in mind that this metric is sampled at scrape time. So it is only an approximation of the actual number of requests in flight. We should assume the actual utilization is higher and request increases sooner.
      grafana_dashboard_id: alerts-max_inferences_per_engine
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-max_inferences_per_engine?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_datasource_id: mimir-runway
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "2029158470"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment,model_engine,shard,stage,tier,type) (
          clamp_min(
            clamp_max(
              sum by (environment,model_engine,shard,stage,tier,type)(max_over_time(model_inferences_in_flight{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[10m]))
              /
              max by (environment,model_engine,shard,stage,tier,type)(min_over_time(model_inferences_max_concurrent{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[10m]))
              ,
              1)
          ,
          0)
        )
      promql_template_1: |
        max by(environment,model_engine,shard,stage,tier,type) (
          clamp_min(
            clamp_max(
              sum by (environment,model_engine,shard,stage,tier,type)(max_over_time(model_inferences_in_flight{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[10m]))
              /
              max by (environment,model_engine,shard,stage,tier,type)(min_over_time(model_inferences_max_concurrent{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[10m]))
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s3
    expr: |
      gitlab_component_saturation:ratio{component="max_concurrent_inferences_per_engine",type="ai-gateway"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="max_concurrent_inferences_per_engine"}
  - alert: component_saturation_slo_out_of_bounds:open_fds
    for: 5m
    annotations:
      title: The Open file descriptor utilization per instance resource of the {{
        $labels.type }} service ({{ $labels.stage }} stage) has a saturation exceeding
        SLO and is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Open file descriptor utilization per instance resource:

        Open file descriptor utilization per instance.

        Saturation on file descriptor limits may indicate a resource-descriptor leak in the application.

        As a temporary fix, you may want to consider restarting the affected process.
      grafana_dashboard_id: alerts-sat_open_fds
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_open_fds?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_datasource_id: mimir-runway
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1001792825"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment,instance,job,shard,stage,tier,type) (
          clamp_min(
            clamp_max(
              (
                process_open_fds{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
                /
                process_max_fds{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              )
              or
              (
                ruby_file_descriptors{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
                /
                ruby_process_max_fds{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              )
              ,
              1)
          ,
          0)
        )
      promql_template_1: |
        max by(environment,instance,job,shard,stage,tier,type) (
          clamp_min(
            clamp_max(
              (
                process_open_fds{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
                /
                process_max_fds{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              )
              or
              (
                ruby_file_descriptors{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
                /
                ruby_process_max_fds{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      pager: pagerduty
      rules_domain: general
      severity: s2
    expr: |
      gitlab_component_saturation:ratio{component="open_fds",type="ai-gateway"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="open_fds"}
  - alert: component_saturation_slo_out_of_bounds:runway_container_cpu_utilization
    for: 5m
    annotations:
      title: The Runway Container CPU Utilization resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage) has a saturation exceeding SLO and
        is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Runway Container CPU Utilization resource:

        Container CPU utilization of the Runway service distributed across all container instances.

        For scaling, refer to https://cloud.google.com/run/docs/configuring/services/cpu.
      grafana_dashboard_id: alerts-sat_runway_container_cpu
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_runway_container_cpu?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_datasource_id: mimir-runway
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1050857443"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment,location,region,revision_name,shard,type) (
          clamp_min(
            clamp_max(
              histogram_quantile(0.9999, sum by(le, environment,location,region,revision_name,shard,type)
                (
                  avg_over_time(
                    stackdriver_cloud_run_revision_run_googleapis_com_container_cpu_utilizations_bucket{job="runway-exporter",environment="{{ $labels.environment }}",type="{{ $labels.type }}"}[30m]
                  )
                )
              )
              ,
              1)
          ,
          0)
        )
      promql_template_1: |
        max by(environment,location,region,revision_name,shard,type) (
          clamp_min(
            clamp_max(
              histogram_quantile(0.9999, sum by(le, environment,location,region,revision_name,shard,type)
                (
                  avg_over_time(
                    stackdriver_cloud_run_revision_run_googleapis_com_container_cpu_utilizations_bucket{job="runway-exporter",environment="{{ $labels.environment }}",type="{{ $labels.type }}"}[30m]
                  )
                )
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
    expr: |
      gitlab_component_saturation:ratio{component="runway_container_cpu_utilization",type="ai-gateway"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="runway_container_cpu_utilization"}
  - alert: component_saturation_slo_out_of_bounds:runway_container_instance_utilization
    for: 5m
    annotations:
      title: The Runway Container Instance Utilization resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage) has a saturation exceeding SLO and
        is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Runway Container Instance Utilization resource:

        Container instance utilization of the Runway service.

        For scaling, refer to https://cloud.google.com/run/docs/configuring/max-instances.
      grafana_dashboard_id: alerts-sat_runway_container_instance
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_runway_container_instance?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_datasource_id: mimir-runway
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1738137433"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment,location,region,revision_name,shard,type) (
          clamp_min(
            clamp_max(
              sum by (environment,location,region,revision_name,shard,type) (
                stackdriver_cloud_run_revision_run_googleapis_com_container_instance_count{job="runway-exporter",state="active",environment="{{ $labels.environment }}",type="{{ $labels.type }}"}
              )
              /
              100
              ,
              1)
          ,
          0)
        )
      promql_template_1: |
        max by(environment,location,region,revision_name,shard,type) (
          clamp_min(
            clamp_max(
              sum by (environment,location,region,revision_name,shard,type) (
                stackdriver_cloud_run_revision_run_googleapis_com_container_instance_count{job="runway-exporter",state="active",environment="{{ $labels.environment }}",type="{{ $labels.type }}"}
              )
              /
              100
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
    expr: |
      gitlab_component_saturation:ratio{component="runway_container_instance_utilization",type="ai-gateway"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="runway_container_instance_utilization"}
  - alert: component_saturation_slo_out_of_bounds:runway_container_max_concurrent_requests
    for: 5m
    annotations:
      title: The Runway Max Concurrent Requests resource of the {{ $labels.type }}
        service ({{ $labels.stage }} stage) has a saturation exceeding SLO and is
        close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Runway Max Concurrent Requests resource:

        Max number of concurrent requests being served by each container instance of the Runway service.

        For scaling, refer to https://cloud.google.com/run/docs/configuring/concurrency.
      grafana_dashboard_id: alerts-sat_runway_container_max_con_reqs
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_runway_container_max_con_reqs?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_datasource_id: mimir-runway
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "4285373877"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment,location,region,revision_name,shard,type) (
          clamp_min(
            clamp_max(
              histogram_quantile(0.9999, sum by(le, environment,location,region,revision_name,shard,type)
                (
                  rate(
                    stackdriver_cloud_run_revision_run_googleapis_com_container_max_request_concurrencies_bucket{job="runway-exporter",state="active",environment="{{ $labels.environment }}",type="{{ $labels.type }}"}[30m]
                  )
                )
              ) / 100
              ,
              1)
          ,
          0)
        )
      promql_template_1: |
        max by(environment,location,region,revision_name,shard,type) (
          clamp_min(
            clamp_max(
              histogram_quantile(0.9999, sum by(le, environment,location,region,revision_name,shard,type)
                (
                  rate(
                    stackdriver_cloud_run_revision_run_googleapis_com_container_max_request_concurrencies_bucket{job="runway-exporter",state="active",environment="{{ $labels.environment }}",type="{{ $labels.type }}"}[30m]
                  )
                )
              ) / 100
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
    expr: |
      gitlab_component_saturation:ratio{component="runway_container_max_concurrent_requests",type="ai-gateway"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="runway_container_max_concurrent_requests"}
  - alert: component_saturation_slo_out_of_bounds:runway_container_memory_utilization
    for: 5m
    annotations:
      title: The Runway Container Memory Utilization resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage) has a saturation exceeding SLO and
        is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Runway Container Memory Utilization resource:

        Container memory utilization of the Runway service distributed across all container instances.

        For scaling, refer to https://cloud.google.com/run/docs/configuring/services/memory-limits.
      grafana_dashboard_id: alerts-sat_runway_container_memory
      grafana_dashboard_link: https://dashboards.gitlab.net/d/alerts-sat_runway_container_memory?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage
        }}
      grafana_datasource_id: mimir-runway
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "377718254"
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment,region,revision_name,shard,type) (
          clamp_min(
            clamp_max(
              histogram_quantile(0.9999, sum by(le, environment,region,revision_name,shard,type)
                (
                  avg_over_time(
                    stackdriver_cloud_run_revision_run_googleapis_com_container_memory_utilizations_bucket{job="runway-exporter",environment="{{ $labels.environment }}",type="{{ $labels.type }}"}[30m]
                  )
                )
              )
              ,
              1)
          ,
          0)
        )
      promql_template_1: |
        max by(environment,region,revision_name,shard,type) (
          clamp_min(
            clamp_max(
              histogram_quantile(0.9999, sum by(le, environment,region,revision_name,shard,type)
                (
                  avg_over_time(
                    stackdriver_cloud_run_revision_run_googleapis_com_container_memory_utilizations_bucket{job="runway-exporter",environment="{{ $labels.environment }}",type="{{ $labels.type }}"}[30m]
                  )
                )
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/README.md
    labels:
      alert_type: cause
      rules_domain: general
      severity: s4
    expr: |
      gitlab_component_saturation:ratio{component="runway_container_memory_utilization",type="ai-gateway"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="runway_container_memory_utilization"}
