# WARNING. DO NOT EDIT THIS FILE BY HAND. USE ./thanos-rules-jsonnet/service-component-alerts.jsonnet TO GENERATE IT
# YOUR CHANGES WILL BE OVERRIDDEN
groups:
- name: 'Service Component Alerts: mailroom'
  interval: 1m
  partial_response_strategy: warn
  rules:
  - alert: MailroomServiceEmailReceiverErrorSLOViolation
    for: 2m
    annotations:
      title: The email_receiver SLI of the mailroom service (`{{ $labels.stage }}`
        stage) has an error rate violating SLO
      description: |
        Monitors ratio between all received emails and received emails which could not be processed for some reason. This is different from just the sidekiq jobs in `emailsProcessed` as it uses specific errors to measure errors rather than job failures.

        Currently the error-rate is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: mailroom-main/mailroom-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/mailroom-main/mailroom-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "212053046"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(gitlab_transaction_event_email_receiver_error_total{environment="{{ $labels.environment }}",error!="Gitlab::Email::AutoGeneratedEmailError",stage="{{ $labels.stage }}"}[5m])
        )
      runbook: docs/mailroom/README.md
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: service_desk
      rules_domain: general
      severity: s3
      sli_type: error
      slo_alert: "yes"
      user_impacting: "yes"
      window: 1h
    expr: |
      (
        (
          gitlab_component_errors:ratio_1h{component="email_receiver",env="ops",monitor="global",type="mailroom"}
          > (14.4 * 0.300000)
        )
        and
        (
          gitlab_component_errors:ratio_5m{component="email_receiver",env="ops",monitor="global",type="mailroom"}
          > (14.4 * 0.300000)
        )
      )
      and on(env,environment,tier,type,stage,component)
      (
        sum by(env,environment,tier,type,stage,component) (gitlab_component_ops:rate_1h{component="email_receiver",env="ops",monitor="global",type="mailroom"}) >= 1
      )
  - alert: MailroomServiceEmailReceiverErrorSLOViolation
    for: 2m
    annotations:
      title: The email_receiver SLI of the mailroom service (`{{ $labels.stage }}`
        stage) has an error rate violating SLO
      description: |
        Monitors ratio between all received emails and received emails which could not be processed for some reason. This is different from just the sidekiq jobs in `emailsProcessed` as it uses specific errors to measure errors rather than job failures.

        Currently the error-rate is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: mailroom-main/mailroom-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/mailroom-main/mailroom-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "212053046"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(gitlab_transaction_event_email_receiver_error_total{environment="{{ $labels.environment }}",error!="Gitlab::Email::AutoGeneratedEmailError",stage="{{ $labels.stage }}"}[5m])
        )
      runbook: docs/mailroom/README.md
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: service_desk
      rules_domain: general
      severity: s3
      sli_type: error
      slo_alert: "yes"
      user_impacting: "yes"
      window: 6h
    expr: |
      (
        (
          gitlab_component_errors:ratio_6h{component="email_receiver",env="ops",monitor="global",type="mailroom"}
          > (6 * 0.300000)
        )
        and
        (
          gitlab_component_errors:ratio_30m{component="email_receiver",env="ops",monitor="global",type="mailroom"}
          > (6 * 0.300000)
        )
      )
      and on(env,environment,tier,type,stage,component)
      (
        sum by(env,environment,tier,type,stage,component) (gitlab_component_ops:rate_6h{component="email_receiver",env="ops",monitor="global",type="mailroom"}) >= 0.16667
      )
  - alert: MailroomServiceEmailReceiverTrafficCessation
    for: 5m
    annotations:
      title: The email_receiver SLI of the mailroom service (`{{ $labels.stage }}`
        stage) has not received any traffic in the past 30m
      description: |
        Monitors ratio between all received emails and received emails which could not be processed for some reason. This is different from just the sidekiq jobs in `emailsProcessed` as it uses specific errors to measure errors rather than job failures.

        This alert signifies that the SLI is reporting a cessation of traffic; the signal is present, but is zero.
      grafana_dashboard_id: mailroom-main/mailroom-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/mailroom-main/mailroom-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1545803555"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(gitlab_sli_sidekiq_execution_total{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",worker=~"EmailReceiverWorker|ServiceDeskEmailReceiverWorker"}[5m])
        )
      runbook: docs/mailroom/README.md
    labels:
      aggregation: component
      alert_class: traffic_cessation
      alert_type: cause
      feature_category: service_desk
      rules_domain: general
      severity: s3
      sli_type: ops
      slo_alert: "no"
      user_impacting: "yes"
    expr: |
      gitlab_component_ops:rate_30m{component="email_receiver",env="ops",monitor="global",stage="main",type="mailroom"} == 0
      and
      gitlab_component_ops:rate_30m{component="email_receiver",env="ops",monitor="global",stage="main",type="mailroom"} offset 1h >= 0.16666666666666666
  - alert: MailroomServiceEmailReceiverTrafficAbsent
    for: 30m
    annotations:
      title: The email_receiver SLI of the mailroom service (`{{ $labels.stage }}`
        stage) has not reported any traffic in the past 30m
      description: |
        Monitors ratio between all received emails and received emails which could not be processed for some reason. This is different from just the sidekiq jobs in `emailsProcessed` as it uses specific errors to measure errors rather than job failures.

        This alert signifies that the SLI was previously reporting traffic, but is no longer - the signal is absent.

        This could be caused by a change to the metrics used in the SLI, or by the service not receiving traffic.
      grafana_dashboard_id: mailroom-main/mailroom-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/mailroom-main/mailroom-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1545803555"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(gitlab_sli_sidekiq_execution_total{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",worker=~"EmailReceiverWorker|ServiceDeskEmailReceiverWorker"}[5m])
        )
      runbook: docs/mailroom/README.md
    labels:
      aggregation: component
      alert_class: traffic_cessation
      alert_type: cause
      feature_category: service_desk
      rules_domain: general
      severity: s3
      sli_type: ops
      slo_alert: "no"
      user_impacting: "yes"
    expr: |
      gitlab_component_ops:rate_5m{component="email_receiver",env="ops",monitor="global",stage="main",type="mailroom"} offset 1h
      unless
      gitlab_component_ops:rate_5m{component="email_receiver",env="ops",monitor="global",stage="main",type="mailroom"}
  - alert: MailroomServiceEmailsProcessedErrorSLOViolation
    for: 2m
    annotations:
      title: The emailsProcessed SLI of the mailroom service (`{{ $labels.stage }}`
        stage) has an error rate violating SLO
      description: |
        Monitors incoming emails delivered from the imap inbox and processed through Sidekiq's `EmailReceiverWorker`. Note that since Mailroom has poor observability, we use Sidekiq metrics for this, and this could lead to certain Sidekiq problems being attributed to Mailroom

        Currently the error-rate is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: mailroom-main/mailroom-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/mailroom-main/mailroom-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "225761444"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(gitlab_sli_sidekiq_execution_error_total{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",worker=~"EmailReceiverWorker|ServiceDeskEmailReceiverWorker"}[5m])
        )
      runbook: docs/mailroom/README.md
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: error
      slo_alert: "yes"
      user_impacting: "yes"
      window: 1h
    expr: |
      (
        (
          gitlab_component_errors:ratio_1h{component="emailsProcessed",env="ops",monitor="global",type="mailroom"}
          > (14.4 * 0.000500)
        )
        and
        (
          gitlab_component_errors:ratio_5m{component="emailsProcessed",env="ops",monitor="global",type="mailroom"}
          > (14.4 * 0.000500)
        )
      )
      and on(env,environment,tier,type,stage,component)
      (
        sum by(env,environment,tier,type,stage,component) (gitlab_component_ops:rate_1h{component="emailsProcessed",env="ops",monitor="global",type="mailroom"}) >= 1
      )
  - alert: MailroomServiceEmailsProcessedErrorSLOViolation
    for: 2m
    annotations:
      title: The emailsProcessed SLI of the mailroom service (`{{ $labels.stage }}`
        stage) has an error rate violating SLO
      description: |
        Monitors incoming emails delivered from the imap inbox and processed through Sidekiq's `EmailReceiverWorker`. Note that since Mailroom has poor observability, we use Sidekiq metrics for this, and this could lead to certain Sidekiq problems being attributed to Mailroom

        Currently the error-rate is {{ $value | humanizePercentage }}.
      grafana_dashboard_id: mailroom-main/mailroom-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/mailroom-main/mailroom-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "225761444"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(gitlab_sli_sidekiq_execution_error_total{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",worker=~"EmailReceiverWorker|ServiceDeskEmailReceiverWorker"}[5m])
        )
      runbook: docs/mailroom/README.md
    labels:
      aggregation: component
      alert_class: slo_violation
      alert_type: symptom
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: error
      slo_alert: "yes"
      user_impacting: "yes"
      window: 6h
    expr: |
      (
        (
          gitlab_component_errors:ratio_6h{component="emailsProcessed",env="ops",monitor="global",type="mailroom"}
          > (6 * 0.000500)
        )
        and
        (
          gitlab_component_errors:ratio_30m{component="emailsProcessed",env="ops",monitor="global",type="mailroom"}
          > (6 * 0.000500)
        )
      )
      and on(env,environment,tier,type,stage,component)
      (
        sum by(env,environment,tier,type,stage,component) (gitlab_component_ops:rate_6h{component="emailsProcessed",env="ops",monitor="global",type="mailroom"}) >= 0.16667
      )
  - alert: MailroomServiceEmailsProcessedTrafficCessation
    for: 5m
    annotations:
      title: The emailsProcessed SLI of the mailroom service (`{{ $labels.stage }}`
        stage) has not received any traffic in the past 30m
      description: |
        Monitors incoming emails delivered from the imap inbox and processed through Sidekiq's `EmailReceiverWorker`. Note that since Mailroom has poor observability, we use Sidekiq metrics for this, and this could lead to certain Sidekiq problems being attributed to Mailroom

        This alert signifies that the SLI is reporting a cessation of traffic; the signal is present, but is zero.
      grafana_dashboard_id: mailroom-main/mailroom-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/mailroom-main/mailroom-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1411619640"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(gitlab_sli_sidekiq_execution_total{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",worker=~"EmailReceiverWorker|ServiceDeskEmailReceiverWorker"}[5m])
        )
      runbook: docs/mailroom/README.md
    labels:
      aggregation: component
      alert_class: traffic_cessation
      alert_type: cause
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: ops
      slo_alert: "no"
      user_impacting: "yes"
    expr: |
      gitlab_component_ops:rate_30m{component="emailsProcessed",env="ops",monitor="global",stage="main",type="mailroom"} == 0
      and
      gitlab_component_ops:rate_30m{component="emailsProcessed",env="ops",monitor="global",stage="main",type="mailroom"} offset 1h >= 0.16666666666666666
  - alert: MailroomServiceEmailsProcessedTrafficAbsent
    for: 30m
    annotations:
      title: The emailsProcessed SLI of the mailroom service (`{{ $labels.stage }}`
        stage) has not reported any traffic in the past 30m
      description: |
        Monitors incoming emails delivered from the imap inbox and processed through Sidekiq's `EmailReceiverWorker`. Note that since Mailroom has poor observability, we use Sidekiq metrics for this, and this could lead to certain Sidekiq problems being attributed to Mailroom

        This alert signifies that the SLI was previously reporting traffic, but is no longer - the signal is absent.

        This could be caused by a change to the metrics used in the SLI, or by the service not receiving traffic.
      grafana_dashboard_id: mailroom-main/mailroom-overview
      grafana_dashboard_link: https://dashboards.gitlab.net/d/mailroom-main/mailroom-overview?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: "6"
      grafana_panel_id: "1411619640"
      grafana_variables: environment,stage
      promql_template_1: |
        sum by (env,environment,tier,stage) (
          rate(gitlab_sli_sidekiq_execution_total{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",worker=~"EmailReceiverWorker|ServiceDeskEmailReceiverWorker"}[5m])
        )
      runbook: docs/mailroom/README.md
    labels:
      aggregation: component
      alert_class: traffic_cessation
      alert_type: cause
      feature_category: not_owned
      pager: pagerduty
      rules_domain: general
      severity: s2
      sli_type: ops
      slo_alert: "no"
      user_impacting: "yes"
    expr: |
      gitlab_component_ops:rate_5m{component="emailsProcessed",env="ops",monitor="global",stage="main",type="mailroom"} offset 1h
      unless
      gitlab_component_ops:rate_5m{component="emailsProcessed",env="ops",monitor="global",stage="main",type="mailroom"}
